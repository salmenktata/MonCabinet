# Architecture Technique - Qadhya

## ğŸ—ï¸ Vue d'Ensemble

Qadhya est une plateforme SaaS juridique construite autour de **Next.js 15 (App Router)**, d'une base **PostgreSQL 15 + pgvector** pour les embeddings, d'un stockage **MinIO (S3)** et d'un cache **Redis**. L'authentification est gÃ©rÃ©e via **JWT HttpOnly** (lib `jose`).

L'architecture intÃ¨gre un pipeline RAG complet pour un assistant IA juridique bilingue (FR/AR).

## ğŸ“ Principes Architecturaux

### 1. Feature-Based Organization
```
app/
â”œâ”€â”€ (auth)/          # Authentification
â”œâ”€â”€ (dashboard)/     # Interface avocat
â”œâ”€â”€ (super-admin)/   # Administration
â””â”€â”€ api/             # 42+ routes API
```

### 2. Server Components par DÃ©faut
Utilisation maximale des Server Components Next.js 15 pour performance optimale.

### 3. Type Safety
TypeScript strict avec Zod pour la validation runtime.

## ğŸ”§ Stack Technique

### Frontend
- **Next.js 15** (App Router, Server Components)
- **TailwindCSS** + **shadcn/ui** (50+ composants)
- **Zustand** pour l'Ã©tat global
- **React Hook Form + Zod** pour les formulaires
- **@react-pdf/renderer** pour PDF
- **i18n** : Support FR/AR avec RTL

### Backend
- **PostgreSQL 15** + **pgvector** (`lib/db/postgres.ts`)
- **JWT HttpOnly** pour l'auth (`lib/auth/session.ts`)
- **MinIO** pour le stockage (`lib/storage/minio.ts`)
- **Redis** pour le cache (`lib/cache/redis.ts`)

### IA / Pipeline RAG (20 services)
- **Embeddings** : OpenAI text-embedding-3-large / Ollama nomic-embed-text
- **LLM** : Groq (prioritaire) / Anthropic Claude / OpenAI
- **Re-ranking** : Cross-encoder Xenova/ms-marco-MiniLM-L-6-v2
- **Clustering** : UMAP + HDBSCAN pour documents similaires
- **Traduction** : Groq avec cache Redis 30 jours
- **Token counting** : gpt-tokenizer pour budget prÃ©cis

Services clÃ©s (`lib/ai/`) :
- `rag-chat-service.ts` : Orchestrateur RAG principal
- `embeddings-service.ts` : GÃ©nÃ©ration et cache embeddings
- `knowledge-base-service.ts` : Gestion base de connaissances
- `reranker-service.ts` : Re-ranking cross-encoder
- `translation-service.ts` : Traduction ARâ†”FR
- `feedback-service.ts` : Boost dynamique basÃ© feedback
- `clustering-service.ts` : Clustering sÃ©mantique HDBSCAN
- `related-documents-service.ts` : Documents similaires

### IntÃ©grations
- **WhatsApp Business API** : Messagerie clients
- **Google Drive** : Sync documents (optionnel)
- **Flouci** : Paiements tunisiens
- **Email** : Resend / Brevo

## ğŸ—„ï¸ ModÃ¨le de DonnÃ©es (50+ tables)

Les migrations sont versionnÃ©es dans `db/migrations/` (40+ fichiers).

### Tables Core
- `users` : comptes et rÃ´les
- `profiles` : informations cabinet
- `clients` : clients du cabinet
- `dossiers` : dossiers juridiques
- `actions` : tÃ¢ches par dossier
- `echeances` : dÃ©lais et audiences
- `documents` : piÃ¨ces et documents
- `factures` : facturation

### Tables IA / RAG
- `knowledge_base` : documents base de connaissances
- `knowledge_base_chunks` : chunks pour RAG
- `knowledge_base_embeddings` : embeddings vectoriels
- `chat_messages` : historique conversations
- `chat_message_feedback` : feedback utilisateurs
- `document_embeddings` : embeddings documents utilisateur

### Tables IntÃ©grations
- `whatsapp_conversations` : conversations WhatsApp
- `whatsapp_messages` : messages WhatsApp
- `payment_transactions` : paiements Flouci

## ğŸ” SÃ©curitÃ© & Auth

- **JWT HttpOnly** avec signature `HS256` (30 jours)
- Cookies sÃ©curisÃ©s (HTTPS en prod)
- **Hashing mots de passe** : bcrypt (10 rounds)
- **ContrÃ´les d'accÃ¨s** via `user_id` et vÃ©rifications rÃ´le
- **Rate limiting** : en mÃ©moire / Redis
- VÃ©rification HMAC pour webhooks (WhatsApp, Flouci)

Points clÃ©s :
- `middleware.ts` protÃ¨ge les routes UI
- Les API/Actions valident la session avec `getSession()`

## ğŸ§  Pipeline RAG

```
1. Question utilisateur (AR/FR)
         â†“
2. DÃ©tection langue + traduction si AR
         â†“
3. Query expansion (synonymes juridiques)
         â†“
4. Recherche multi-sources :
   - knowledge_base (lois, jurisprudence)
   - document_embeddings (docs utilisateur)
   - Full-text search
         â†“
5. Re-ranking cross-encoder
         â†“
6. Boost dynamique (feedback utilisateurs)
         â†“
7. Assemblage contexte (budget tokens)
         â†“
8. GÃ©nÃ©ration LLM (Groq/Claude)
         â†“
9. RÃ©ponse avec sources citÃ©es
```

## ğŸ³ DÃ©ploiement

- Docker Compose : Next.js + Postgres + MinIO + Redis
- Build Next.js en `output: 'standalone'`
- Healthcheck applicatif : `app/api/health/route.ts`
- Backup : Script pg_dump + MinIO sync

## ğŸ§¾ ObservabilitÃ©

- Logger centralisÃ© : `lib/logger.ts`
- Tracking coÃ»ts IA : `lib/ai/usage-tracker.ts`
- Audit d'activitÃ© cÃ´tÃ© auth/administration

## ğŸ§­ Historique

Supabase a Ã©tÃ© retirÃ© au profit d'une stack autoâ€‘hÃ©bergÃ©e. Les dÃ©tails historiques sont documentÃ©s dans `docs/migration/MIGRATION_SUPABASE.md`.
