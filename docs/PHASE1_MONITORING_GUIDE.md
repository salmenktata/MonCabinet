# Guide Monitoring Phase 1 - Quick Wins Performance

**Objectif** : Collecter m√©triques pendant 7 jours (10-17 Feb 2026) pour valider gains Phase 1

---

## üéØ M√©triques Cl√©s √† Surveiller

### 1Ô∏è‚É£ Latency RAG Search (P50/P95)

**Objectif** : P50 <2s, P95 <5s (actuellement ~4-6s et ~10-15s)

**Commandes** :

```bash
# 1. Extraire latencies depuis logs (derni√®res 24h)
ssh root@84.247.165.187 'docker logs moncabinet-nextjs --since 24h | grep "RAG Search.*Latency"' > rag_latencies.log

# 2. Parser latencies en millisecondes
cat rag_latencies.log | grep -oP 'Latency: \K[0-9]+' > latencies.txt

# 3. Calculer statistiques
cat latencies.txt | awk '
BEGIN {
  count = 0
  sum = 0
}
{
  latencies[count] = $1
  sum += $1
  count++
}
END {
  # Moyenne
  avg = sum / count
  print "Moyenne: " avg "ms (" avg/1000 "s)"

  # Trier pour percentiles
  asort(latencies)

  # P50 (m√©diane)
  p50_idx = int(count * 0.5)
  print "P50: " latencies[p50_idx] "ms (" latencies[p50_idx]/1000 "s)"

  # P95
  p95_idx = int(count * 0.95)
  print "P95: " latencies[p95_idx] "ms (" latencies[p95_idx]/1000 "s)"

  # Min/Max
  print "Min: " latencies[1] "ms"
  print "Max: " latencies[count] "ms"

  # Total queries
  print "Total queries: " count
}'
```

**Fr√©quence** : 1√ó/jour

**Alerte** : Si P95 >8s pendant 3 jours cons√©cutifs ‚Üí investigation

---

### 2Ô∏è‚É£ Throughput Indexation

**Objectif** : >30 docs/heure (actuellement ~12)

**Commandes** :

```bash
# 1. Tunnel SSH vers DB prod
ssh -f -N -L 5434:localhost:5432 root@84.247.165.187

# 2. Compter documents index√©s dans p√©riode
psql -h localhost -p 5434 -U moncabinet -d moncabinet << 'EOF'
SELECT
  DATE(updated_at) AS jour,
  COUNT(*) AS docs_indexes,
  COUNT(*) / 24.0 AS docs_par_heure
FROM knowledge_base
WHERE is_indexed = true
  AND updated_at >= '2026-02-10'
  AND updated_at <= '2026-02-17'
GROUP BY DATE(updated_at)
ORDER BY jour;
EOF

# 3. Dur√©e moyenne indexation (depuis logs)
ssh root@84.247.165.187 'docker logs moncabinet-nextjs --since 168h | grep "Indexing completed"' | \
  awk '{
    # Extraire temps (format: "XXXXms")
    match($0, /([0-9]+)ms/, arr)
    if (arr[1] != "") {
      sum += arr[1]
      count++
    }
  }
  END {
    if (count > 0) {
      print "Dur√©e moyenne indexation: " sum/count "ms (" sum/count/1000 "s)"
      print "Total docs index√©s: " count
      print "Throughput estim√©: " count/168 " docs/heure (sur 7 jours)"
    }
  }'

# 4. Jobs d'indexation (succ√®s vs √©checs)
ssh root@84.247.165.187 'docker logs moncabinet-nextjs --since 168h' | \
  grep -E "Indexing (completed|failed)" | \
  awk '{
    if ($0 ~ /completed/) success++
    if ($0 ~ /failed/) failed++
  }
  END {
    total = success + failed
    print "Jobs compl√©t√©s: " success
    print "Jobs √©chou√©s: " failed
    print "Taux succ√®s: " (success/total*100) "%"
  }'
```

**Fr√©quence** : 1√ó/jour

**Alerte** : Si throughput <15 docs/heure pendant 3 jours ‚Üí investigation

---

### 3Ô∏è‚É£ Cache Hit Rate

**Objectif** : >20% (actuellement ~5%)

**Commandes** :

```bash
# 1. Redis stats globales
ssh root@84.247.165.187 'docker exec moncabinet-redis redis-cli INFO stats' | grep -E "keyspace_hits|keyspace_misses"

# Exemple output:
# keyspace_hits:12543
# keyspace_misses:2341

# Calculer hit rate:
# Hit rate = keyspace_hits / (keyspace_hits + keyspace_misses) * 100
# = 12543 / (12543 + 2341) * 100 = 84.3%

# 2. Comptage entr√©es search cache
ssh root@84.247.165.187 'docker exec moncabinet-redis redis-cli KEYS "search:*"' | wc -l

# 3. Distribution TTL cache
ssh root@84.247.165.187 'docker exec moncabinet-redis redis-cli --scan --pattern "search:*"' | \
  while read key; do
    ttl=$(ssh root@84.247.165.187 "docker exec moncabinet-redis redis-cli TTL '$key'")
    echo "$ttl"
  done | \
  awk '{
    sum += $1
    count++
  }
  END {
    print "TTL moyen: " sum/count "s (" sum/count/60 " min)"
    print "Entr√©es totales: " count
  }'

# 4. Top queries cach√©es (si logs disponibles)
ssh root@84.247.165.187 'docker logs moncabinet-nextjs --since 168h | grep "SearchCache.*HIT"' | \
  head -20
```

**Fr√©quence** : 1√ó/jour

**Alerte** : Si hit rate <10% pendant 3 jours ‚Üí ajuster threshold √† 0.70

---

### 4Ô∏è‚É£ Index DB Usage

**Objectif** : >100 scans/jour par index

**Commandes** :

```bash
# 1. Stats index usage
psql -h localhost -p 5434 -U moncabinet -d moncabinet << 'EOF'
SELECT
  schemaname,
  relname AS table_name,
  indexrelname AS index_name,
  idx_scan AS total_scans,
  idx_tup_read AS tuples_read,
  idx_tup_fetch AS tuples_fetched,
  pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
WHERE indexrelname IN (
  'idx_kb_structured_metadata_knowledge_base_id',
  'idx_kb_legal_relations_source_target',
  'idx_knowledge_base_category_language'
)
ORDER BY idx_scan DESC;
EOF

# 2. √âvolution scans (comparaison jour J vs J-1)
# Note: Ex√©cuter cette requ√™te 2 jours cons√©cutifs et comparer

# 3. Ratio cache PostgreSQL
psql -h localhost -p 5434 -U moncabinet -d moncabinet << 'EOF'
SELECT
  sum(blks_hit)::FLOAT / nullif(sum(blks_hit) + sum(blks_read), 0) AS cache_hit_ratio,
  sum(blks_hit) AS cache_hits,
  sum(blks_read) AS disk_reads
FROM pg_stat_database
WHERE datname = 'moncabinet';
EOF
# Objectif: cache_hit_ratio > 0.95 (95%)

# 4. Queries lentes (si activ√©)
psql -h localhost -p 5434 -U moncabinet -d moncabinet << 'EOF'
SELECT
  query,
  calls,
  total_exec_time / 1000 AS total_time_sec,
  mean_exec_time / 1000 AS avg_time_sec,
  max_exec_time / 1000 AS max_time_sec
FROM pg_stat_statements
WHERE query LIKE '%kb_%'
ORDER BY mean_exec_time DESC
LIMIT 10;
EOF
```

**Fr√©quence** : 1√ó/jour

**Alerte** : Si idx_scan <50/jour apr√®s 3 jours ‚Üí index non utilis√©

---

## üîç Monitoring Sant√© Syst√®me

### Ollama (CPU/RAM)

```bash
# 1. Stats CPU/RAM temps r√©el
ssh root@84.247.165.187 'journalctl -u ollama -f'

# 2. Historique CPU (derni√®res 24h)
ssh root@84.247.165.187 'journalctl -u ollama --since "24 hours ago" | grep -i cpu'

# 3. Crashes Ollama
ssh root@84.247.165.187 'journalctl -u ollama --since "7 days ago" | grep -iE "crash|panic|fatal"'

# 4. Uptime Ollama
ssh root@84.247.165.187 'systemctl status ollama | grep Active'

# 5. Mod√®les charg√©s
ssh root@84.247.165.187 'curl -s http://localhost:11434/api/ps'
```

**Alerte** : Si CPU >400% constant >1h ‚Üí r√©duire concurrency

---

### PostgreSQL

```bash
# 1. Connexions actives
psql -h localhost -p 5434 -U moncabinet -d moncabinet << 'EOF'
SELECT
  count(*) AS active_connections,
  max_conn,
  max_conn - count(*) AS available_connections
FROM pg_stat_activity, (SELECT setting::int AS max_conn FROM pg_settings WHERE name='max_connections') AS s
GROUP BY max_conn;
EOF

# 2. Derni√®re VACUUM/ANALYZE
psql -h localhost -p 5434 -U moncabinet -d moncabinet << 'EOF'
SELECT
  schemaname,
  relname,
  last_vacuum,
  last_autovacuum,
  last_analyze,
  last_autoanalyze
FROM pg_stat_user_tables
WHERE relname LIKE 'kb_%' OR relname = 'knowledge_base'
ORDER BY last_analyze DESC;
EOF

# 3. Taille DB et tables
psql -h localhost -p 5434 -U moncabinet -d moncabinet << 'EOF'
SELECT
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
  pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) AS indexes_size
FROM pg_tables
WHERE schemaname = 'public' AND (tablename LIKE 'kb_%' OR tablename = 'knowledge_base')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
EOF

# 4. Fragmentation (dead tuples)
psql -h localhost -p 5434 -U moncabinet -d moncabinet << 'EOF'
SELECT
  schemaname,
  tablename,
  n_live_tup,
  n_dead_tup,
  round(n_dead_tup::FLOAT / nullif(n_live_tup, 0) * 100, 2) AS dead_ratio_percent
FROM pg_stat_user_tables
WHERE schemaname = 'public'
ORDER BY dead_ratio_percent DESC NULLS LAST
LIMIT 10;
EOF
# Si dead_ratio > 20% ‚Üí VACUUM recommand√©
```

**Alerte** : Si cache_hit_ratio <0.90 ‚Üí augmenter shared_buffers

---

### Redis

```bash
# 1. Memory usage
ssh root@84.247.165.187 'docker exec moncabinet-redis redis-cli INFO memory' | grep -E "used_memory_human|used_memory_peak_human|maxmemory"

# 2. Connected clients
ssh root@84.247.165.187 'docker exec moncabinet-redis redis-cli INFO clients' | grep connected_clients

# 3. Evicted keys (m√©moire satur√©e)
ssh root@84.247.165.187 'docker exec moncabinet-redis redis-cli INFO stats' | grep evicted_keys

# 4. Uptime
ssh root@84.247.165.187 'docker exec moncabinet-redis redis-cli INFO server' | grep uptime_in_days
```

**Alerte** : Si evicted_keys >0 ‚Üí augmenter maxmemory Redis

---

### Container NextJS

```bash
# 1. Sant√© container
ssh root@84.247.165.187 'docker ps --filter name=moncabinet-nextjs --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"'

# 2. Logs erreurs (derni√®res 24h)
ssh root@84.247.165.187 'docker logs moncabinet-nextjs --since 24h | grep -iE "error|exception|failed"' | head -50

# 3. Memory usage container
ssh root@84.247.165.187 'docker stats moncabinet-nextjs --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}"'

# 4. Restart count
ssh root@84.247.165.187 'docker inspect moncabinet-nextjs | jq ".[0].RestartCount"'
```

**Alerte** : Si RestartCount >3 en 24h ‚Üí investigation urgente

---

## üìä Dashboard Quotidien

### Script automatis√© (copier-coller)

```bash
#!/bin/bash
# daily-metrics.sh - Collecte m√©triques quotidiennes Phase 1

echo "=========================================="
echo "üìä M√âTRIQUES QUOTIDIENNES - $(date +%Y-%m-%d)"
echo "=========================================="

# 1. RAG Latency
echo ""
echo "1Ô∏è‚É£ RAG Search Latency (derni√®res 24h)"
echo "--------------------------------------"
ssh root@84.247.165.187 'docker logs moncabinet-nextjs --since 24h | grep "RAG Search.*Latency"' | \
  grep -oP 'Latency: \K[0-9]+' | \
  awk '{
    latencies[NR] = $1
    sum += $1
  }
  END {
    asort(latencies)
    count = NR
    print "Total queries: " count
    print "Moyenne: " sum/count "ms (" sum/count/1000 "s)"
    print "P50: " latencies[int(count*0.5)] "ms"
    print "P95: " latencies[int(count*0.95)] "ms"
  }'

# 2. Throughput indexation
echo ""
echo "2Ô∏è‚É£ Throughput Indexation (derni√®res 24h)"
echo "--------------------------------------"
ssh root@84.247.165.187 'docker logs moncabinet-nextjs --since 24h | grep "Indexing completed"' | wc -l | \
  awk '{print "Documents index√©s: " $1 " (" $1 " docs/jour, " $1/24 " docs/heure)"}'

# 3. Cache hit rate
echo ""
echo "3Ô∏è‚É£ Cache Hit Rate"
echo "--------------------------------------"
ssh root@84.247.165.187 'docker exec moncabinet-redis redis-cli INFO stats' | \
  grep -E "keyspace_hits|keyspace_misses" | \
  awk -F: '
    /keyspace_hits/ {hits=$2}
    /keyspace_misses/ {misses=$2}
    END {
      total = hits + misses
      rate = (hits / total) * 100
      print "Hits: " hits
      print "Misses: " misses
      print "Hit rate: " rate "%"
    }
  '

# 4. Index DB scans
echo ""
echo "4Ô∏è‚É£ Index DB Usage"
echo "--------------------------------------"
ssh -f -N -L 5434:localhost:5432 root@84.247.165.187 2>/dev/null
sleep 1
psql -h localhost -p 5434 -U moncabinet -d moncabinet -t -c "
  SELECT
    indexrelname || ': ' || idx_scan || ' scans'
  FROM pg_stat_user_indexes
  WHERE indexrelname LIKE 'idx_kb_%'
  ORDER BY idx_scan DESC
  LIMIT 10;
" | grep -v "^$"

# 5. Sant√© Ollama
echo ""
echo "5Ô∏è‚É£ Sant√© Ollama"
echo "--------------------------------------"
ssh root@84.247.165.187 'systemctl status ollama --no-pager | grep -E "Active|Memory"'

echo ""
echo "=========================================="
echo "‚úÖ Collecte termin√©e - $(date +%H:%M)"
echo "=========================================="
```

**Usage** :
```bash
chmod +x daily-metrics.sh
./daily-metrics.sh > metrics-$(date +%Y-%m-%d).log
```

**Fr√©quence** : 1√ó/jour (matin 9h recommand√©)

---

## üö® Alertes Automatiques (Optionnel)

### Script d√©tection anomalies

```bash
#!/bin/bash
# check-anomalies.sh - D√©tecte anomalies et envoie alerte

ALERT_EMAIL="votre@email.com"
THRESHOLD_P95=8000  # 8s en ms

# Check P95 latency
p95=$(ssh root@84.247.165.187 'docker logs moncabinet-nextjs --since 24h | grep "RAG Search.*Latency"' | \
  grep -oP 'Latency: \K[0-9]+' | \
  sort -n | \
  awk '{all[NR]=$1} END {print all[int(NR*0.95)]}')

if [ "$p95" -gt "$THRESHOLD_P95" ]; then
  echo "‚ö†Ô∏è ALERTE: P95 latency trop √©lev√© ($p95 ms > $THRESHOLD_P95 ms)" | \
    mail -s "[Qadhya] Alerte Performance RAG" $ALERT_EMAIL
fi

# Check Ollama crashes
crashes=$(ssh root@84.247.165.187 'journalctl -u ollama --since "24 hours ago" | grep -ic crash')

if [ "$crashes" -gt 0 ]; then
  echo "‚ö†Ô∏è ALERTE: Ollama a crash√© $crashes fois en 24h" | \
    mail -s "[Qadhya] Alerte Ollama Crash" $ALERT_EMAIL
fi

# Check container restarts
restarts=$(ssh root@84.247.165.187 'docker inspect moncabinet-nextjs | jq ".[0].RestartCount"')

if [ "$restarts" -gt 3 ]; then
  echo "‚ö†Ô∏è ALERTE: Container NextJS red√©marr√© $restarts fois" | \
    mail -s "[Qadhya] Alerte Container Restart" $ALERT_EMAIL
fi
```

**Cron** (ex√©cuter toutes les 6h) :
```bash
0 */6 * * * /path/to/check-anomalies.sh
```

---

## üìù Checklist Hebdomadaire

**Jour 1 (10 Feb)** :
- [ ] D√©ploiement Phase 1 en production
- [ ] V√©rifier sant√© post-d√©ploiement
- [ ] Baseline : Collecter m√©triques initiales

**Jours 2-6 (11-15 Feb)** :
- [ ] Ex√©cuter `daily-metrics.sh` chaque matin
- [ ] V√©rifier alertes anomalies
- [ ] Noter incidents dans rapport

**Jour 7 (17 Feb)** :
- [ ] Collecter m√©triques finales
- [ ] Calculer moyennes semaine
- [ ] Remplir template rapport (PHASE1_WEEKLY_REPORT_TEMPLATE.md)
- [ ] D√©cision : Pause / Ajustements / Debug

---

## üîó R√©f√©rences

- **Rapport template** : `docs/PHASE1_WEEKLY_REPORT_TEMPLATE.md`
- **Documentation Phase 1** : `docs/PHASE1_PRESENTATION.md`
- **Script d√©ploiement** : `scripts/deploy-phase1-production.sh`
- **Script tests perf** : `scripts/test-phase1-performance.ts`

---

**Version** : 1.0
**Derni√®re mise √† jour** : 10 f√©vrier 2026
