# Configuration RAG - Qadhya

Guide complet pour configurer et activer le syst√®me RAG (Retrieval-Augmented Generation) de l'assistant juridique Qadhya.

---

## ‚öôÔ∏è Variables d'Environnement Principales

### RAG_ENABLED vs OLLAMA_ENABLED

**Distinction critique** :

| Variable | R√¥le | Impact |
|----------|------|--------|
| `RAG_ENABLED` | **Feature flag RAG** | Active/d√©sactive les features RAG avanc√©es (chunking, metadata, classification) |
| `OLLAMA_ENABLED` | **Moteur de recherche** | Active/d√©sactive la recherche s√©mantique (embeddings + vectoriel) |

### Configuration Recommand√©e

#### Production (Qualit√© Maximale)
```bash
RAG_ENABLED=true          # ‚úÖ Toutes les features RAG activ√©es
OLLAMA_ENABLED=true       # ‚úÖ Recherche s√©mantique activ√©e
OPENAI_API_KEY=sk-...     # ‚úÖ Embeddings OpenAI (1536-dim, qualit√© optimale)
```

**R√©sultat** : RAG complet avec embeddings OpenAI (scores 75-85%).

---

#### D√©veloppement Local (√âconomique)
```bash
RAG_ENABLED=true          # ‚úÖ Features RAG activ√©es
OLLAMA_ENABLED=true       # ‚úÖ Ollama local (0‚Ç¨)
# OPENAI_API_KEY non d√©fini ‚Üí fallback Ollama embeddings (1024-dim)
```

**R√©sultat** : RAG complet avec Ollama (scores 65-70%, 0‚Ç¨).

---

#### Mode D√©grad√© (Sans Recherche S√©mantique)
```bash
RAG_ENABLED=false         # ‚ùå Features RAG d√©sactiv√©es
OLLAMA_ENABLED=false      # ‚ùå Recherche s√©mantique d√©sactiv√©e
```

**R√©sultat** : Pas de RAG, assistant IA sans contexte documentaire (hallucinations possibles).

---

## üìä Matrice de Comportement

| `RAG_ENABLED` | `OLLAMA_ENABLED` | `OPENAI_API_KEY` | Comportement |
|---------------|------------------|------------------|--------------|
| ‚úÖ `true` | ‚úÖ `true` | ‚úÖ D√©fini | **OPTIMAL** : RAG complet + OpenAI embeddings (75-85% scores) |
| ‚úÖ `true` | ‚úÖ `true` | ‚ùå Non d√©fini | **BON** : RAG complet + Ollama embeddings (65-70% scores, 0‚Ç¨) |
| ‚ùå `false` | ‚úÖ `true` | ‚úÖ D√©fini | **SIMPLE** : Recherche s√©mantique basique sans features avanc√©es |
| ‚ùå `false` | ‚ùå `false` | N/A | **D√âSACTIV√â** : Pas de RAG, assistant sans contexte |

---

## üîß Variables de Configuration RAG

### Chunking (D√©coupage Documents)

```bash
RAG_CHUNK_SIZE=1024       # Taille chunks (caract√®res)
RAG_CHUNK_OVERLAP=100     # Chevauchement entre chunks
```

**Recommendations** :
- **Jurisprudence** : 1800 chars (d√©cisions longues)
- **Codes** : 600 chars (articles courts)
- **Doctrine** : 1500 chars (analyses moyennes)

### Recherche S√©mantique

```bash
RAG_MAX_RESULTS=15                # Nombre max r√©sultats retourn√©s (5 ‚Üí 15 Sprint 1)
RAG_SIMILARITY_THRESHOLD=0.7      # Seuil similarit√© global
RAG_THRESHOLD_KB=0.50             # Seuil KB sp√©cifique (0.65 ‚Üí 0.50 Sprint 1)
RAG_MAX_CONTEXT_TOKENS=6000       # Tokens max contexte (2000 ‚Üí 6000 Sprint 1)
```

**Seuils adaptatifs par type** :
- `RAG_THRESHOLD_DOCUMENTS=0.7`
- `RAG_THRESHOLD_JURISPRUDENCE=0.6`
- `RAG_THRESHOLD_KB=0.50`

### Diversit√© Sources

```bash
RAG_MAX_CHUNKS_PER_SOURCE=2  # Max chunks par document source
RAG_MIN_SOURCES=2            # Minimum sources diff√©rentes requises
```

√âvite concentration sur un seul document.

---

## üöÄ Activation √âtape par √âtape

### 1. Activer Features RAG

```bash
# .env.local ou .env.production.local
RAG_ENABLED=true
```

**Active** :
- Chunking documents intelligent
- Classification juridique automatique
- Extraction m√©tadonn√©es enrichies
- Analyse qualit√© documents

### 2. Activer Recherche S√©mantique

#### Option A : Ollama (Local, Gratuit)

```bash
OLLAMA_ENABLED=true
OLLAMA_BASE_URL=http://localhost:11434

# Mod√®les requis (√† t√©l√©charger) :
# ollama pull qwen3-embedding:0.6b  # Embeddings (1024-dim)
# ollama pull qwen2.5:3b            # Chat (optionnel)
```

**Commandes Docker** :
```bash
docker-compose up -d ollama
docker exec qadhya-ollama ollama pull qwen3-embedding:0.6b
```

#### Option B : OpenAI (Cloud, ~$2-5/mois)

```bash
OLLAMA_ENABLED=true  # ‚ö†Ô∏è Requis m√™me avec OpenAI
OPENAI_API_KEY=sk-...

# Embeddings automatiques : text-embedding-3-small (1536-dim)
```

**Avantages OpenAI** :
- Scores +10-15% (65-70% ‚Üí 75-85%)
- Embeddings 1536-dim (vs 1024-dim Ollama)
- Pas de d√©pendance infrastructure locale

### 3. V√©rifier Activation

```bash
# V√©rifier variables
env | grep -E "(RAG|OLLAMA|OPENAI)"

# Tester recherche s√©mantique
curl http://localhost:7002/api/test/kb-debug
```

**R√©ponse attendue** :
```json
{
  "RAG_ENABLED": "true",
  "OLLAMA_ENABLED": "true",
  "semanticSearchActive": true,
  "embeddingProvider": "openai" | "ollama"
}
```

---

## üîç Debugging Configuration

### Sympt√¥me : "Recherche s√©mantique d√©sactiv√©e"

**Causes possibles** :

1. `OLLAMA_ENABLED=false` ou non d√©fini
   ```bash
   # Fix :
   OLLAMA_ENABLED=true
   ```

2. Ollama non d√©marr√© (si mode local)
   ```bash
   # V√©rifier :
   curl http://localhost:11434/api/tags

   # Fix :
   docker-compose up -d ollama
   ```

3. Mod√®le embeddings manquant
   ```bash
   # V√©rifier :
   ollama list | grep embedding

   # Fix :
   ollama pull qwen3-embedding:0.6b
   ```

### Sympt√¥me : "Pas de r√©sultats KB trouv√©s"

**Causes possibles** :

1. KB non index√©e
   ```bash
   # V√©rifier :
   curl http://localhost:7002/api/admin/monitoring/metrics | jq '.kbStats'

   # Fix : D√©clencher indexation
   curl -X POST http://localhost:7002/api/admin/index-kb
   ```

2. Seuil trop √©lev√©
   ```bash
   # Temporairement baisser :
   RAG_THRESHOLD_KB=0.40  # 0.50 ‚Üí 0.40
   ```

3. Embeddings incompatibles (mixing Ollama + OpenAI)
   ```bash
   # R√©indexer avec provider uniforme :
   npx tsx scripts/reindex-all-kb-openai.ts
   ```

---

## üìà Optimisation Performance

### Latence

```bash
# Timeout recherche bilingue
BILINGUAL_SEARCH_TIMEOUT_MS=60000  # 90s ‚Üí 60s (parall√©lisation Sprint 2)

# Cache Redis
SEARCH_CACHE_THRESHOLD=0.75        # Hit si similarit√© ‚â• 75%
```

### Qualit√©

```bash
# Sprint 1 : OpenAI embeddings
OPENAI_API_KEY=sk-...

# Sprint 2 : Query expansion
ENABLE_QUERY_EXPANSION=true

# Sprint 3 : Hybrid search
# (Auto-activ√© si PostgreSQL 12+ avec pg_trgm)
```

---

## üéØ Cas d'Usage

### Assistant IA Conversationnel

```bash
RAG_ENABLED=true
OLLAMA_ENABLED=true
RAG_MAX_RESULTS=10
RAG_THRESHOLD_KB=0.50
```

### Consultation Juridique Formelle

```bash
RAG_ENABLED=true
OLLAMA_ENABLED=true
OPENAI_API_KEY=sk-...       # Pr√©cision maximale
RAG_MAX_RESULTS=15
RAG_THRESHOLD_KB=0.60       # Seuil plus strict
RAG_MAX_CONTEXT_TOKENS=8000  # Contexte enrichi
```

### Indexation Batch (√âconomique)

```bash
RAG_ENABLED=true
OLLAMA_ENABLED=true
# OPENAI_API_KEY non d√©fini ‚Üí Ollama 0‚Ç¨

# Batch progressif
KB_BATCH_SIZE=5
```

---

## üìö Ressources

- **Audit RAG** : `docs/RAG_DEPLOYMENT_FINAL_REPORT.md`
- **Optimisations** : `docs/RAG_QUALITY_IMPROVEMENTS.md`
- **Monitoring** : Dashboard `/super-admin/monitoring?tab=kb-quality`
- **Tests** : `npx tsx scripts/test-rag-complete-e2e.ts`

---

## ‚ö†Ô∏è Points de Vigilance

1. **JAMAIS** sync KB locale ‚Üí prod (KB prod = crawl uniquement)
2. **TOUJOURS** v√©rifier `OLLAMA_ENABLED=true` apr√®s d√©ploiement
3. **Pr√©f√©rer** OpenAI embeddings en production (qualit√© +10-15%)
4. **Surveiller** budget OpenAI (seuil alerte $5 restant)
5. **R√©indexer** avec m√™me provider (pas de mixing Ollama/OpenAI)

---

**Derni√®re mise √† jour** : 13 f√©vrier 2026
**Version** : Phase 1 Plan Optimisation RAG
