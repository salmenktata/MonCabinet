# Fix RAG Embeddings Dimension Mismatch

**Date** : 16 fÃ©vrier 2026
**ProblÃ¨me** : Assistant IA rÃ©pond "Ù„Ù… Ø£Ø¬Ø¯ ÙˆØ«Ø§Ø¦Ù‚ Ø°Ø§Øª ØµÙ„Ø©" malgrÃ© 165+ chunks pertinents en KB
**Root Cause** : Mismatch dimensions embeddings query (1024-dim Ollama) vs KB (1536-dim OpenAI)

---

## ğŸ” Diagnostic

### Ã‰tat Actuel KB
```sql
-- 165 chunks sur lÃ©gitime dÃ©fense avec embeddings OpenAI
SELECT COUNT(*) FROM knowledge_base_chunks kbc
JOIN knowledge_base kb ON kbc.knowledge_base_id = kb.id
WHERE kb.is_active = true
  AND kbc.embedding_openai IS NOT NULL
  AND kbc.content_tsvector @@ plainto_tsquery('simple', 'Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ø´Ø±Ø¹ÙŠ');
-- RÃ©sultat: 165 chunks

-- Mais seulement 34 avec embeddings Ollama
SELECT COUNT(*) FROM knowledge_base_chunks kbc
JOIN knowledge_base kb ON kbc.knowledge_base_id = kb.id
WHERE kb.is_active = true
  AND kbc.embedding IS NOT NULL
  AND kbc.content_tsvector @@ plainto_tsquery('simple', 'Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ø´Ø±Ø¹ÙŠ');
-- RÃ©sultat: 34 chunks
```

### Configuration Actuelle
```typescript
// lib/ai/operations-config.ts - assistant-ia
embeddings: isDev
  ? { provider: 'ollama', model: 'qwen3-embedding:0.6b', dimensions: 1024 }
  : { provider: 'openai', model: 'text-embedding-3-small', dimensions: 1536 },
```

**En production** : NODE_ENV=production + OPENAI_API_KEY dÃ©finie â†’ devrait utiliser OpenAI
**Mais** : Query gÃ©nÃ¨re probablement embedding Ollama (1024-dim) Ã  cause de fallback/cache

---

## âœ… Solution DÃ©finitive

### Option A : Forcer OpenAI Embeddings Partout (RECOMMANDÃ‰)

**Avantages** :
- QualitÃ© supÃ©rieure (text-embedding-3-small meilleur que qwen3)
- CohÃ©rence 100% (mÃªme dimension query + KB)
- CoÃ»t acceptable (~$2-5/mois)

**ImplÃ©mentation** :

1. **Modifier configuration pour FORCER OpenAI en production** :
```typescript
// lib/ai/operations-config.ts - assistant-ia
embeddings: {
  provider: 'openai',  // Forcer OpenAI mÃªme si OLLAMA_ENABLED=true
  model: 'text-embedding-3-small',
  dimensions: 1536
},
```

2. **Ajouter validation dimension avant recherche** :
```typescript
// lib/ai/knowledge-base-service.ts - searchKnowledgeBaseHybrid
const queryEmbedding = await generateEmbedding(query, {
  operationName: operationName as any,
})

// VALIDATION CRITIQUE : VÃ©rifier dimension avant recherche SQL
const expectedDim = useOpenAI ? 1536 : 1024
if (queryEmbedding.embedding.length !== expectedDim) {
  throw new Error(
    `Embedding dimension mismatch: got ${queryEmbedding.embedding.length}, expected ${expectedDim} for provider ${useOpenAI ? 'OpenAI' : 'Ollama'}`
  )
}
```

3. **Purger cache Redis embeddings** (une seule fois aprÃ¨s fix) :
```bash
ssh root@84.247.165.187 "docker exec qadhya-redis redis-cli KEYS 'embedding:*' | xargs -L 100 docker exec qadhya-redis redis-cli DEL"
```

### Option B : Forcer Ollama Partout (Gratuit mais moins performant)

**Avantages** :
- Gratuit (0â‚¬/mois)
- Local, pas de dÃ©pendance externe

**InconvÃ©nients** :
- **NÃ©cessite rÃ©indexation COMPLÃˆTE de la KB** (2958 docs Ã— 8.5 chunks = 25K chunks)
- Temps estimÃ© : 48-72h (25K chunks Ã— 10s/chunk)
- QualitÃ© infÃ©rieure Ã  OpenAI

**ImplÃ©mentation** :
```typescript
// lib/ai/operations-config.ts - assistant-ia
embeddings: {
  provider: 'ollama',
  model: 'qwen3-embedding:0.6b',
  dimensions: 1024
},
```

Puis rÃ©indexer toute la KB :
```bash
npx tsx scripts/reindex-kb-full.ts --force --provider=ollama
```

---

## ğŸ›¡ï¸ PrÃ©vention RÃ©gressions Futures

### 1. Tests E2E Automatiques

CrÃ©er un test qui vÃ©rifie la cohÃ©rence embeddings query â†” KB :

```typescript
// tests/rag/embeddings-consistency.test.ts
import { generateEmbedding } from '@/lib/ai/embeddings-service'
import { searchKnowledgeBaseHybrid } from '@/lib/ai/knowledge-base-service'

describe('RAG Embeddings Consistency', () => {
  it('should use same embedding dimension for query and KB search', async () => {
    const query = "Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ø´Ø±Ø¹ÙŠ"

    // GÃ©nÃ©rer embedding query (comme assistant-ia)
    const queryEmbedding = await generateEmbedding(query, {
      operationName: 'assistant-ia'
    })

    // VÃ©rifier dimension attendue production
    if (process.env.NODE_ENV === 'production') {
      expect(queryEmbedding.embedding.length).toBe(1536) // OpenAI
      expect(queryEmbedding.provider).toBe('openai')
    }

    // VÃ©rifier que la recherche retourne des rÃ©sultats
    const results = await searchKnowledgeBaseHybrid(query, {
      limit: 5,
      threshold: 0.30,
      operationName: 'assistant-ia'
    })

    expect(results.length).toBeGreaterThan(0) // Au moins 1 rÃ©sultat
  })

  it('should match KB chunks embedding provider in production', async () => {
    // VÃ©rifier que la majoritÃ© des chunks utilisent OpenAI en production
    const { rows } = await db.query(`
      SELECT
        COUNT(*) FILTER (WHERE embedding_openai IS NOT NULL) as openai_count,
        COUNT(*) FILTER (WHERE embedding IS NOT NULL) as ollama_count
      FROM knowledge_base_chunks kbc
      JOIN knowledge_base kb ON kbc.knowledge_base_id = kb.id
      WHERE kb.is_active = true
    `)

    if (process.env.NODE_ENV === 'production') {
      expect(rows[0].openai_count).toBeGreaterThan(rows[0].ollama_count * 10) // 90%+ OpenAI
    }
  })
})
```

Ajouter au CI/CD :
```yaml
# .github/workflows/test-rag.yml
name: Test RAG Consistency

on:
  push:
    branches: [main]
    paths:
      - 'lib/ai/**'
      - 'lib/categories/**'

jobs:
  test-rag:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run RAG consistency tests
        run: npm run test:rag:consistency
```

### 2. Health Check Enrichi

Ajouter vÃ©rification dimension embeddings dans `/api/health` :

```typescript
// app/api/health/route.ts
export async function GET() {
  const { rows } = await db.query(`
    SELECT
      COUNT(*) FILTER (WHERE embedding_openai IS NOT NULL) as openai_chunks,
      COUNT(*) FILTER (WHERE embedding IS NOT NULL) as ollama_chunks,
      COUNT(*) as total_chunks
    FROM knowledge_base_chunks kbc
    JOIN knowledge_base kb ON kbc.knowledge_base_id = kb.id
    WHERE kb.is_active = true
  `)

  const embeddingConfig = {
    production: {
      expectedProvider: 'openai',
      expectedDimension: 1536,
      currentProvider: rows[0].openai_chunks > rows[0].ollama_chunks ? 'openai' : 'ollama',
      coverage: {
        openai: rows[0].openai_chunks,
        ollama: rows[0].ollama_chunks,
        total: rows[0].total_chunks
      }
    }
  }

  // Alerter si mismatch
  const isConsistent = process.env.NODE_ENV === 'production'
    ? rows[0].openai_chunks > rows[0].ollama_chunks * 0.9 // 90%+ OpenAI requis
    : true

  return NextResponse.json({
    ...healthData,
    rag: {
      ...ragStatus,
      embeddingsConsistency: isConsistent ? 'ok' : 'misconfigured',
      embeddingConfig,
      warning: !isConsistent ? 'KB chunks primarily use Ollama but production should use OpenAI' : undefined
    }
  })
}
```

### 3. Alertes Email Automatiques

Ajouter vÃ©rification dans le cron quotidien :

```bash
# scripts/cron-check-rag-embeddings.sh
#!/bin/bash
set -euo pipefail

echo "[$(date)] VÃ©rification cohÃ©rence embeddings RAG..."

# Check embedding provider coverage
EMBEDDING_STATS=$(docker exec -i qadhya-postgres psql -U moncabinet -d qadhya -t -A -c "
  SELECT
    COUNT(*) FILTER (WHERE embedding_openai IS NOT NULL) as openai,
    COUNT(*) FILTER (WHERE embedding IS NOT NULL) as ollama
  FROM knowledge_base_chunks kbc
  JOIN knowledge_base kb ON kbc.knowledge_base_id = kb.id
  WHERE kb.is_active = true;
")

OPENAI_COUNT=$(echo $EMBEDDING_STATS | cut -d'|' -f1)
OLLAMA_COUNT=$(echo $EMBEDDING_STATS | cut -d'|' -f2)

# Alert si OpenAI < 90% en production
if [ "$OPENAI_COUNT" -lt $(($OLLAMA_COUNT * 9)) ]; then
  echo "âš ï¸  ALERTE: KB utilise principalement Ollama ($OLLAMA_COUNT) au lieu d'OpenAI ($OPENAI_COUNT)"
  # Envoyer email via /api/admin/alerts/send
  curl -X POST http://localhost:7002/api/admin/alerts/send \
    -H "X-Cron-Secret: $CRON_SECRET" \
    -H "Content-Type: application/json" \
    -d "{
      \"subject\": \"âš ï¸ RAG Embeddings Mismatch DÃ©tectÃ©\",
      \"message\": \"KB utilise principalement Ollama ($OLLAMA_COUNT chunks) au lieu d'OpenAI ($OPENAI_COUNT chunks) en production. Risque de 0 rÃ©sultats dans l'Assistant IA.\"
    }"
fi
```

Ajouter au crontab :
```cron
0 8 * * * /opt/qadhya/scripts/cron-check-rag-embeddings.sh >> /var/log/qadhya/rag-embeddings-check.log 2>&1
```

### 4. Documentation & Guidelines

CrÃ©er un guide pour l'Ã©quipe :

```markdown
# ğŸ“š Guide RAG Embeddings - RÃ¨gles Critiques

## âš ï¸ RÃˆGLE #1 : JAMAIS changer le provider embeddings sans migration

Si vous modifiez `operations-config.ts` pour changer le provider embeddings :
1. âŒ **NE PAS** dÃ©ployer directement
2. âœ… CrÃ©er un script de migration qui rÃ©indexe toute la KB
3. âœ… Tester sur un petit sous-ensemble (100 docs) avant migration complÃ¨te
4. âœ… VÃ©rifier avec `npm run test:rag:consistency`

## âš ï¸ RÃˆGLE #2 : Production = OpenAI embeddings UNIQUEMENT

- Assistant IA en production DOIT utiliser OpenAI (1536-dim)
- Ollama rÃ©servÃ© au dev local uniquement
- CoÃ»t acceptable : ~$2-5/mois

## âš ï¸ RÃˆGLE #3 : Toujours valider aprÃ¨s changement config

AprÃ¨s TOUT changement dans `operations-config.ts` ou `embeddings-service.ts` :
```bash
# 1. Tester cohÃ©rence embeddings
npm run test:rag:consistency

# 2. VÃ©rifier health check
curl https://qadhya.tn/api/health | jq '.rag.embeddingsConsistency'
# Attendu: "ok"

# 3. Tester recherche rÃ©elle
curl -X POST https://qadhya.tn/api/chat \
  -H "Content-Type: application/json" \
  -d '{"question": "Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ø´Ø±Ø¹ÙŠ"}' \
  | jq '.sources | length'
# Attendu: > 0
```

## ğŸ”„ Checklist Avant DÃ©ploiement

- [ ] Tests E2E RAG passent
- [ ] Health check `embeddingsConsistency: "ok"`
- [ ] Recherche test retourne rÃ©sultats
- [ ] Aucune modification provider embeddings sans migration
- [ ] Documentation mise Ã  jour si changement architecture
```

---

## ğŸ“Š MÃ©triques de Suivi

Ajouter au dashboard monitoring (`/super-admin/monitoring?tab=rag-health`) :

- **Embedding Provider Coverage** : Graphique camembert OpenAI vs Ollama
- **Dimension Consistency** : % chunks alignÃ©s avec config production
- **Query Success Rate** : % queries retournant â‰¥1 rÃ©sultat
- **Average Results per Query** : Nombre moyen de sources retournÃ©es

---

## ğŸš€ Plan d'Action ImmÃ©diat

### Phase 1 : Fix Production (PrioritÃ© 1 - Aujourd'hui)
1. âœ… Valider que OpenAI key fonctionne
2. âœ… Purger cache Redis embeddings
3. âœ… Tester query lÃ©gitime dÃ©fense â†’ doit retourner rÃ©sultats
4. â³ Surveiller logs 24h pour confirmer fix

### Phase 2 : Tests & PrÃ©vention (PrioritÃ© 2 - Cette semaine)
1. â³ CrÃ©er tests E2E embeddings consistency
2. â³ Enrichir health check avec dimension validation
3. â³ Ajouter cron alerte embeddings mismatch
4. â³ Documenter guidelines Ã©quipe

### Phase 3 : Monitoring (PrioritÃ© 3 - Semaine prochaine)
1. â³ Ajouter mÃ©triques dashboard RAG health
2. â³ IntÃ©grer tests dans CI/CD
3. â³ CrÃ©er runbook intervention

---

## ğŸ¯ RÃ©sultats Attendus

**Avant Fix** :
- Query "Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ø´Ø±Ø¹ÙŠ" â†’ 0 sources (Ù„Ù… Ø£Ø¬Ø¯ ÙˆØ«Ø§Ø¦Ù‚)
- Logs : "KB Hybrid Search Provider: ollama" (mismatch)

**AprÃ¨s Fix** :
- Query "Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ø´Ø±Ø¹ÙŠ" â†’ 5-10 sources pertinentes
- Logs : "KB Hybrid Search Provider: openai" (cohÃ©rent avec KB)
- Health check : `embeddingsConsistency: "ok"`
- Tests E2E : âœ… PASS

---

**Auteur** : SystÃ¨me RAG Qadhya
**Review** : Ã€ valider par Ã©quipe technique
**Deadline** : Phase 1 aujourd'hui, Phase 2-3 sous 2 semaines
