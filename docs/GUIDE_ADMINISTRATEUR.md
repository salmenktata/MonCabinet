# Guide Administrateur - Qadhya RAG Juridique

**Version** : 1.0
**Date** : 11 FÃ©vrier 2026
**Public** : Administrateurs systÃ¨me, Super-admins Qadhya
**DurÃ©e lecture** : ~25 minutes

---

## Table des MatiÃ¨res

1. [Introduction](#1-introduction)
2. [Architecture SystÃ¨me](#2-architecture-systÃ¨me)
3. [Gestion Base de Connaissances](#3-gestion-base-de-connaissances)
4. [Monitoring & MÃ©triques](#4-monitoring--mÃ©triques)
5. [Gestion Utilisateurs](#5-gestion-utilisateurs)
6. [Optimisations Performance](#6-optimisations-performance)
7. [Sauvegardes & Restauration](#7-sauvegardes--restauration)
8. [SÃ©curitÃ©](#8-sÃ©curitÃ©)
9. [Troubleshooting](#9-troubleshooting)
10. [Maintenance](#10-maintenance)

---

## 1. Introduction

### 1.1 RÃ´le de l'Administrateur

En tant qu'administrateur Qadhya, vous Ãªtes responsable de :

- âœ… **QualitÃ© de la base de connaissances** (500+ docs juridiques)
- âœ… **Performance du systÃ¨me RAG** (latence, prÃ©cision, coÃ»t)
- âœ… **SÃ©curitÃ© et confidentialitÃ©** (donnÃ©es utilisateurs, RGPD)
- âœ… **Monitoring continu** (uptime >99%, dÃ©tection anomalies)
- âœ… **Support niveau 2** (escalade bugs critiques)

### 1.2 AccÃ¨s Interface Admin

1. **URL** : [https://qadhya.tn/super-admin](https://qadhya.tn/super-admin)
2. **Authentification** : Compte super-admin (rÃ´le `ADMIN`)
3. **Dashboard principal** : Vue d'ensemble mÃ©triques clÃ©s

**âš ï¸ SÃ©curitÃ©** : L'accÃ¨s admin est tracÃ©. Toute action critique gÃ©nÃ¨re un log d'audit.

---

## 2. Architecture SystÃ¨me

### 2.1 Stack Technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UTILISATEURS (Avocats)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Next.js 15 (Frontend + API Routes)                â”‚
â”‚   - Chat Interface (React)                                  â”‚
â”‚   - Admin Dashboard (React)                                  â”‚
â”‚   - API REST (/api/*)                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PostgreSQL  â”‚ â”‚    Redis     â”‚ â”‚    MinIO     â”‚
    â”‚  (DonnÃ©es)   â”‚ â”‚   (Cache)    â”‚ â”‚  (Storage)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         Pipeline RAG (lib/ai/)               â”‚
    â”‚  1. Embeddings (Ollama qwen3-embedding)      â”‚
    â”‚  2. Recherche SÃ©mantique (pgvector)          â”‚
    â”‚  3. Multi-Chain Reasoning (4 chains)         â”‚
    â”‚  4. LLM Generation (Fallback chain)          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         LLM Providers (Fallback)             â”‚
    â”‚  1. Ollama (local, gratuit)                  â”‚
    â”‚  2. Groq (cloud, rapide)                     â”‚
    â”‚  3. DeepSeek (cloud, Ã©conomique)             â”‚
    â”‚  4. Anthropic (cloud, premium)               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Base de DonnÃ©es PostgreSQL

#### Tables Critiques

| Table | Taille Moyenne | Description |
|-------|---------------|-------------|
| `knowledge_base` | ~300-500 docs | Documents juridiques indexÃ©s |
| `kb_chunks` | ~5000-10000 chunks | Segments avec embeddings (vector 1024-dim) |
| `kb_structured_metadata` | ~300-500 lignes | MÃ©tadonnÃ©es extraites (tribunal, chambre, date) |
| `kb_legal_relations` | ~300-500 relations | Graphe citations entre documents |
| `rag_feedback` | ~100-200/mois | Feedback utilisateurs (ratings, suggestions) |
| `conversations` | ~500-1000/mois | Historique conversations chat |
| `users` | ~50-100 users | Comptes avocats + admins |
| `ai_usage_logs` | ~10000-20000/mois | Logs appels LLM (coÃ»t, latence, provider) |

#### Indexes Critiques

```sql
-- Recherche sÃ©mantique (HNSW)
CREATE INDEX idx_kb_chunks_embedding ON kb_chunks USING hnsw (embedding vector_cosine_ops);

-- Filtres juridiques
CREATE INDEX idx_kb_metadata_tribunal ON kb_structured_metadata(tribunal);
CREATE INDEX idx_kb_metadata_domain ON kb_structured_metadata(domain);
CREATE INDEX idx_kb_metadata_date ON kb_structured_metadata(date_decision);

-- Performance queries
CREATE INDEX idx_kb_chunks_doc_id ON kb_chunks(document_id);
CREATE INDEX idx_conversations_user_id ON conversations(user_id);
CREATE INDEX idx_ai_usage_logs_provider ON ai_usage_logs(provider, operation, created_at);
```

**âš ï¸ Maintenance** : ExÃ©cuter `VACUUM ANALYZE` hebdomadairement sur tables volumineuses.

### 2.3 Redis Cache

#### Structure Cache

| ClÃ© | TTL | Taille | Description |
|-----|-----|--------|-------------|
| `search:query:{hash}` | 1h | ~5-10 KB | RÃ©sultats recherche sÃ©mantique |
| `embedding:{text_hash}` | 24h | ~4 KB | Embeddings calculÃ©s (1024-dim float) |
| `classification:url:{url_hash}` | 7j | ~2 KB | Classification catÃ©gorie documents |
| `rag:response:{query_hash}` | 5min | ~50-100 KB | RÃ©ponses RAG complÃ¨tes (mode Rapide) |

**ğŸ’¡ Commande utile** :
```bash
# Statistiques cache Redis
redis-cli INFO stats

# Vider cache (ATTENTION : perte temporaire performance)
redis-cli FLUSHDB
```

### 2.4 MinIO Storage

#### Buckets

| Bucket | Taille | Description |
|--------|--------|-------------|
| `documents` | ~500 MB - 2 GB | PDFs indexÃ©s dans KB |
| `web-files` | ~100 MB | Fichiers crawlÃ©s (HTML, DOCX) |
| `avatars` | ~10 MB | Photos profil utilisateurs |
| `uploads` | ~50 MB | Documents temporaires uploadÃ©s |

**Commande vÃ©rification** :
```bash
# Lister buckets
docker exec qadhya-minio mc ls prod

# Taille bucket documents
docker exec qadhya-minio mc du prod/documents
```

---

## 3. Gestion Base de Connaissances

### 3.1 Dashboard KB Quality Review

**URL** : `/super-admin/kb-quality-review`

#### Indicateurs ClÃ©s

| MÃ©trique | Objectif | Actuel | Action si <Objectif |
|----------|----------|--------|-------------------|
| **Health Score Moyen** | >85/100 | - | Valider mÃ©tadonnÃ©es manuellement |
| **Docs Non-IndexÃ©s** | <5% | - | Lancer indexation batch |
| **MÃ©tadonnÃ©es Manquantes** | <10% | - | Re-exÃ©cuter extraction LLM |
| **Citations ValidÃ©es** | >95% | - | Audit manuel citations douteuses |

#### Workflow Validation QualitÃ©

```
1. Filtrer : Docs avec confidence <0.85 OU catÃ©gorie jurisprudence
   â””â”€ Queue priorisÃ©e (par occurrence dans feedbacks)

2. Pour chaque doc :
   a. VÃ©rifier mÃ©tadonnÃ©es (tribunal, chambre, date)
   b. Corriger si nÃ©cessaire (formulaire Ã©ditable)
   c. Valider relations juridiques (citations extraites)
   d. Marquer "ValidÃ©" ou "Rejeter" (suppression KB)

3. Batch validation :
   - Bouton "Valider 10 suivants" â†’ Confirmation en masse
   - Gamification : Points + leaderboard validateurs
```

**ğŸ’¡ Objectif** : Valider 50 docs/semaine minimum (1h/jour)

### 3.2 Ajout de Documents

#### Via Crawling Web

1. **AccÃ©der** : `/super-admin/web-sources`
2. **CrÃ©er source** :
   - Nom : _"Cour de Cassation - ArrÃªts 2024"_
   - Base URL : `https://cassation.tn/arrÃªts/2024`
   - CatÃ©gorie : `jurisprudence`
   - Domaine : `civil` (ou `penal`, `commercial`, etc.)
   - Patterns URL : `/arrÃªt-(\d+)` (regex)
   - Scheduling : Hebdomadaire (lundi 2h UTC)
3. **Lancer crawl initial** : Bouton "Crawler maintenant"
4. **Monitoring** : Onglet "Jobs Crawl" â†’ Statut en temps rÃ©el

#### Via Upload Manual

1. **AccÃ©der** : `/super-admin/knowledge-base/upload`
2. **Upload PDF** : Drag & drop ou sÃ©lection fichier
3. **Remplir mÃ©tadonnÃ©es** :
   - Titre : _"ArrÃªt nÂ° 12345/2024 - Cass. Civ."_
   - CatÃ©gorie : `jurisprudence`
   - Tribunal : `TRIBUNAL_CASSATION`
   - Chambre : `civile`
   - Date dÃ©cision : `2024-06-15`
4. **Indexation automatique** : Batch cron toutes les 5min

**âš ï¸ Limite** : Max 50 MB/fichier, formats supportÃ©s : PDF, DOCX, TXT

### 3.3 Indexation Batch

#### Configuration Cron

**Fichier** : `/opt/qadhya/index-kb-progressive.sh`

```bash
#!/bin/bash
# Indexation progressive (2 docs/appel, 240s timeout)
curl -X POST https://qadhya.tn/api/admin/index-kb \
  -H "Authorization: Bearer $CRON_SECRET" \
  -H "Content-Type: application/json" \
  -d '{"batchSize": 2}' \
  --max-time 240

# Logs dans /var/log/kb-indexing.log
```

**FrÃ©quence** : Toutes les 5 minutes (cron : `*/5 * * * *`)

#### Monitoring Indexation

```bash
# Voir logs temps rÃ©el
tail -f /var/log/kb-indexing.log

# Compter docs indexÃ©s aujourd'hui
grep "Successfully indexed" /var/log/kb-indexing.log | grep "$(date +%Y-%m-%d)" | wc -l

# DÃ©tecter erreurs
grep "ERROR" /var/log/kb-indexing.log | tail -20
```

### 3.4 Re-Chunking

**ProblÃ¨me** : Chunks trop grands (>2500 chars) â†’ Performance dÃ©gradÃ©e

**Solution** : API Re-chunking

```bash
# Dry-run (analyser sans modifier)
curl -X POST https://qadhya.tn/api/admin/kb/rechunk \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -d '{"dryRun": true, "batchSize": 10}'

# ExÃ©cution rÃ©elle
curl -X POST https://qadhya.tn/api/admin/kb/rechunk \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -d '{"dryRun": false, "batchSize": 10, "recomputeEmbeddings": true}'
```

**ParamÃ¨tres** :
- `dryRun` : Simulation sans modifications (dÃ©faut `true`)
- `batchSize` : Nombre docs traitÃ©s en parallÃ¨le (dÃ©faut `10`)
- `recomputeEmbeddings` : Recalculer embeddings aprÃ¨s re-chunking (dÃ©faut `true`)

**ğŸ’¡ Quand re-chunker ?** :
- Health score moyen <70/100
- Latence RAG >8s P95
- Feedbacks "RÃ©ponses trop gÃ©nÃ©rales"

---

## 4. Monitoring & MÃ©triques

### 4.1 Dashboard Production Monitoring

**URL** : `/super-admin/production-monitoring`

#### MÃ©triques Temps RÃ©el

##### 1. Volume
- **Queries/Heure** : Objectif <100 (saturation systÃ¨me si >150)
- **Active Users** : Nombre utilisateurs actifs (derniÃ¨re heure)
- **Peak Concurrency** : RequÃªtes simultanÃ©es max (objectif <10)

##### 2. QualitÃ©
- **Average Rating** : Note moyenne feedbacks (objectif >4.2/5)
- **Hallucination Rate** : % rÃ©ponses avec citations inventÃ©es (objectif <0.1%)
- **Citation Accuracy** : % citations valides (objectif >95%)

##### 3. Performance
- **Latency P50** : MÃ©diane temps rÃ©ponse (objectif <3s)
- **Latency P95** : 95e percentile (objectif <8s)
- **Error Rate** : % requÃªtes en erreur (objectif <0.5%)

##### 4. CoÃ»ts
- **Cost/Query** : CoÃ»t moyen par requÃªte (objectif <0.03 TND)
- **Monthly Budget** : Projection coÃ»t mensuel (objectif <200 TND)

#### Alertes Automatiques

Configuration : `/lib/monitoring/alerts-config.ts`

```typescript
export const ALERT_THRESHOLDS = {
  latency_p95_ms: 8000, // >8s â†’ SMS admin
  error_rate_percent: 0.5, // >0.5% â†’ Email admin
  hallucination_rate_percent: 0.1, // >0.1% â†’ SMS + Email urgent
  cost_per_query_tnd: 0.05, // >0.05 TND â†’ Email quotidien
  queries_per_hour: 150, // >150 â†’ SMS (saturation)
}
```

**Canaux notification** :
- **SMS** : Erreurs critiques (hallucinations, saturation)
- **Email** : Erreurs moyennes (coÃ»t, latence)
- **Slack** : Notifications informatives (nouveaux users, feedbacks)

### 4.2 Dashboard Legal Quality

**URL** : `/super-admin/legal-quality`

#### KPIs Juridiques

| KPI | Calcul | Objectif | Alerte si |
|-----|--------|----------|-----------|
| **Citation Accuracy** | (Citations valides / Total citations) Ã— 100 | >95% | <90% |
| **Hallucination Rate** | (Citations inventÃ©es / Total rÃ©ponses) Ã— 100 | <0.1% | >0.5% |
| **Coverage Score** | (RÃ©ponses >10 sources / Total rÃ©ponses) Ã— 100 | >80% | <60% |
| **Multi-Perspective Rate** | (RÃ©ponses avec analyse contradictoire / Total controversÃ©es) Ã— 100 | >80% | <60% |
| **Freshness Score** | Ã‚ge mÃ©dian sources (jours) | <365j | >730j |
| **Abrogation Detection Rate** | (Abrogations dÃ©tectÃ©es / Total abrogations) Ã— 100 | >90% | <80% |
| **Actionable Rate** | (RÃ©ponses avec recommandations / Total rÃ©ponses) Ã— 100 | >70% | <50% |
| **Lawyer Satisfaction** | Rating moyen avocats (1-5) | >4.2 | <3.8 |

**Export** : Bouton "Export CSV" â†’ Rapport hebdomadaire pour direction

### 4.3 Dashboard Provider Usage

**URL** : `/super-admin/provider-usage`

#### Matrice CoÃ»ts

| Provider | Embedding | Chat | Classification | Total (7j) | Part |
|----------|-----------|------|---------------|-----------|------|
| Ollama (local) | 0.00 TND | 0.00 TND | 0.00 TND | **0.00 TND** | 60% |
| Groq (cloud) | 0.50 TND | 2.30 TND | 0.20 TND | **3.00 TND** | 25% |
| DeepSeek (cloud) | 0.30 TND | 1.50 TND | 0.10 TND | **1.90 TND** | 10% |
| Anthropic (cloud) | 0.20 TND | 1.00 TND | 0.05 TND | **1.25 TND** | 5% |

**Objectif** : Maintenir Ollama >50% (mode Rapide gratuit)

**Action si Ollama <30%** :
1. VÃ©rifier service Ollama : `systemctl status ollama`
2. RedÃ©marrer si down : `systemctl restart ollama`
3. Analyser logs : `journalctl -u ollama -f`

---

## 5. Gestion Utilisateurs

### 5.1 CrÃ©ation Compte Avocat

**URL** : `/super-admin/users/create`

1. **Informations requises** :
   - Nom complet
   - Email professionnel (@avocat.tn recommandÃ©)
   - NumÃ©ro inscription barreau (CNOA)
   - Cabinet juridique
   - Domaines spÃ©cialitÃ© (max 3)

2. **RÃ´le** : `LAWYER` (par dÃ©faut) ou `ADMIN` (super-admins uniquement)

3. **Limites quotidiennes** :
   - Mode Rapide : IllimitÃ©
   - Mode Premium : 20 requÃªtes/jour (plan gratuit) ou IllimitÃ© (plan payant)

4. **Email activation** : Envoi automatique avec lien validation compte

### 5.2 Gestion Plan Utilisateurs

**URL** : `/super-admin/users/{userId}/subscription`

#### Plans Disponibles

| Plan | Prix | RequÃªtes Premium | Support | FonctionnalitÃ©s |
|------|------|------------------|---------|-----------------|
| **Free** | 0 TND/mois | 20/jour | Email (48h) | Mode Rapide illimitÃ© + Mode Premium limitÃ© |
| **Pro** | 50 TND/mois | 200/jour | Email (24h) + Chat | Free + Analyse multi-perspectives + Timeline |
| **Entreprise** | 500 TND/mois | IllimitÃ© | Email (6h) + TÃ©l | Pro + API + Multi-users (10 comptes) |

**ğŸ’¡ Upgrade manuel** :
1. AccÃ©der fiche utilisateur
2. Section "Abonnement" â†’ Changer plan
3. Sauvegarder â†’ Mise Ã  jour immÃ©diate

### 5.3 Suspension Compte

**Raisons suspension** :
- Non-paiement (plan payant)
- Abus systÃ¨me (scraping, spam)
- Violation CGU (partage compte)

**ProcÃ©dure** :
1. `/super-admin/users/{userId}` â†’ Bouton "Suspendre"
2. Motif requis (texte libre)
3. Email automatique Ã  l'utilisateur
4. DonnÃ©es conservÃ©es 90 jours avant suppression

**RÃ©activation** : Bouton "RÃ©activer" (mÃªme page)

---

## 6. Optimisations Performance

### 6.1 Latence RAG

#### Diagnostic

```bash
# Analyser temps rÃ©ponse (P50, P95, P99)
psql -U moncabinet -d qadhya -c "
  SELECT
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY latency_ms) AS p50,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY latency_ms) AS p95,
    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY latency_ms) AS p99
  FROM ai_usage_logs
  WHERE operation = 'chat' AND created_at > NOW() - INTERVAL '7 days';
"
```

#### Optimisations Disponibles

| ProblÃ¨me | Cause | Solution |
|----------|-------|----------|
| P95 >10s | Embeddings lents | Augmenter `OLLAMA_EMBEDDING_CONCURRENCY` (2â†’3) |
| P95 >10s | Recherche sÃ©mantique lente | Reconstruire index HNSW : `REINDEX INDEX idx_kb_chunks_embedding` |
| P95 >10s | Trop de sources (>20) | RÃ©duire `RAG_MAX_SOURCES` (20â†’15) |
| P50 >5s | Cache hit faible | Abaisser `SEARCH_CACHE_THRESHOLD` (0.75â†’0.70) |
| P50 >5s | Multi-chain reasoning lourd | DÃ©sactiver temporairement (mode dÃ©gradÃ©) |

### 6.2 Throughput Indexation

#### Diagnostic

```bash
# Compter docs indexÃ©s/heure
psql -U moncabinet -d qadhya -c "
  SELECT
    DATE_TRUNC('hour', updated_at) AS hour,
    COUNT(*) AS docs_indexed
  FROM knowledge_base
  WHERE is_indexed = true AND updated_at > NOW() - INTERVAL '24 hours'
  GROUP BY hour ORDER BY hour DESC;
"
```

**Objectif** : >10 docs/heure (mode production)

#### Optimisations

1. **Parallel embeddings** : `OLLAMA_EMBEDDING_CONCURRENCY=2` (dÃ©faut)
   - VPS 4 cores â†’ Max 3 concurrent (risque saturation CPU si >3)

2. **Batch size** : `INDEXING_BATCH_SIZE=2` (dÃ©faut)
   - Augmenter Ã  5 si Ollama stable + CPU usage <60%

3. **Streaming PDF** : `USE_STREAMING_PDF=true` (dÃ©faut)
   - RÃ©duit RAM usage -60% (200 MB â†’ 80 MB par PDF)

### 6.3 Cache Hit Rate

#### Diagnostic

```bash
# Stats Redis
redis-cli INFO stats | grep keyspace_hits
redis-cli INFO stats | grep keyspace_misses

# Calcul hit rate
redis-cli INFO stats | awk '/keyspace_hits/{hits=$2} /keyspace_misses/{misses=$2} END{print "Hit rate:", (hits/(hits+misses))*100"%"}'
```

**Objectif** : >80% (cache chaud)

#### Optimisations

1. **Augmenter TTL** :
   - Search cache : 1h â†’ 2h (`SEARCH_CACHE_TTL_HOURS=2`)
   - Embedding cache : 24h â†’ 48h (`EMBEDDING_CACHE_TTL_HOURS=48`)

2. **Abaisser threshold** :
   - Search similarity : 0.75 â†’ 0.70 (`SEARCH_CACHE_THRESHOLD=0.70`)

3. **PrÃ©-remplir cache** (queries frÃ©quentes) :
   ```bash
   # Script : scripts/warmup-cache.sh
   curl -X POST https://qadhya.tn/api/admin/cache/warmup \
     -H "Authorization: Bearer $ADMIN_TOKEN"
   ```

---

## 7. Sauvegardes & Restauration

### 7.1 Sauvegardes Automatiques

#### PostgreSQL

**Cron daily** : 3h UTC (fichier `/opt/qadhya/backup-db.sh`)

```bash
#!/bin/bash
BACKUP_DIR="/opt/qadhya/backups/postgresql"
DATE=$(date +%Y%m%d_%H%M%S)

# Dump complet
docker exec qadhya-postgres pg_dump -U moncabinet -d qadhya -Fc > \
  "$BACKUP_DIR/qadhya_$DATE.dump"

# Compression
gzip "$BACKUP_DIR/qadhya_$DATE.dump"

# Rotation (garder 30 derniers jours)
find "$BACKUP_DIR" -name "qadhya_*.dump.gz" -mtime +30 -delete

# Upload S3 (optionnel)
# aws s3 cp "$BACKUP_DIR/qadhya_$DATE.dump.gz" s3://qadhya-backups/
```

**VÃ©rification** :
```bash
ls -lh /opt/qadhya/backups/postgresql | tail -5
```

#### MinIO (Documents)

**Cron weekly** : Dimanche 4h UTC

```bash
#!/bin/bash
BACKUP_DIR="/opt/qadhya/backups/minio"
DATE=$(date +%Y%m%d)

# Backup bucket documents
docker exec qadhya-minio mc mirror prod/documents "$BACKUP_DIR/$DATE/documents"

# Rotation (garder 12 semaines)
find "$BACKUP_DIR" -maxdepth 1 -type d -mtime +84 -exec rm -rf {} \;
```

### 7.2 Restauration Base de DonnÃ©es

#### ScÃ©nario : Corruption DB

```bash
# 1. ArrÃªter containers
docker stop qadhya-nextjs

# 2. Identifier backup Ã  restaurer
ls -lh /opt/qadhya/backups/postgresql

# 3. Restaurer
gunzip /opt/qadhya/backups/postgresql/qadhya_20260210_030000.dump.gz
docker exec -i qadhya-postgres pg_restore -U moncabinet -d qadhya -c \
  < /opt/qadhya/backups/postgresql/qadhya_20260210_030000.dump

# 4. VÃ©rifier intÃ©gritÃ©
docker exec qadhya-postgres psql -U moncabinet -d qadhya -c "
  SELECT COUNT(*) FROM knowledge_base;
  SELECT COUNT(*) FROM kb_chunks;
"

# 5. RedÃ©marrer
docker start qadhya-nextjs
```

#### ScÃ©nario : Rollback Version Applicative

```bash
# 1. Lister images Docker disponibles
docker images | grep moncabinet

# 2. Identifier version stable prÃ©cÃ©dente
docker tag ghcr.io/salmenktata/moncabinet:latest ghcr.io/salmenktata/moncabinet:rollback
docker pull ghcr.io/salmenktata/moncabinet:sha-XXXXXXX

# 3. Modifier docker-compose.prod.yml
sed -i 's/:latest/:sha-XXXXXXX/' /opt/qadhya/docker-compose.prod.yml

# 4. RedÃ©ployer
cd /opt/qadhya
docker-compose -f docker-compose.prod.yml up -d

# 5. Health check
curl https://qadhya.tn/api/health
```

---

## 8. SÃ©curitÃ©

### 8.1 Audit Logs

**Table** : `audit_logs`

```sql
SELECT
  action, -- 'CREATE_USER', 'DELETE_DOCUMENT', 'CHANGE_SUBSCRIPTION'
  user_id,
  resource_type, -- 'USER', 'DOCUMENT', 'CONVERSATION'
  resource_id,
  details, -- JSON
  ip_address,
  created_at
FROM audit_logs
WHERE created_at > NOW() - INTERVAL '7 days'
ORDER BY created_at DESC
LIMIT 100;
```

**Actions critiques tracÃ©es** :
- CrÃ©ation/suppression utilisateurs
- Modification rÃ´les (LAWYER â†’ ADMIN)
- Suppression documents KB
- AccÃ¨s donnÃ©es sensibles (conversations autres users)
- Modification configuration systÃ¨me

### 8.2 Chiffrement DonnÃ©es

#### En Transit (HTTPS)

- Certificat SSL : Cloudflare mTLS (expire 2036)
- Nginx configurÃ© : `ssl_verify_client on` (mode strict)
- **VÃ©rification** :
  ```bash
  openssl s_client -connect qadhya.tn:443 -servername qadhya.tn
  ```

#### Au Repos

| DonnÃ©es | MÃ©thode | ClÃ© |
|---------|---------|-----|
| ClÃ©s API providers | AES-256-GCM | `ENCRYPTION_KEY` (.env) |
| Mots de passe users | bcrypt (12 rounds) | - |
| Documents MinIO | Chiffrement serveur | MinIO auto |
| Conversations | Non chiffrÃ© (PostgreSQL) | âš ï¸ TODO Phase 8 |

**âš ï¸ CRITIQUE** : Ne jamais supprimer/modifier `ENCRYPTION_KEY` â†’ ClÃ©s API irrÃ©cupÃ©rables

### 8.3 RGPD & ConfidentialitÃ©

#### Droits Utilisateurs

1. **Droit d'accÃ¨s** : Export donnÃ©es (bouton "Exporter mes donnÃ©es" dans profil)
2. **Droit de rectification** : Ã‰dition profil utilisateur
3. **Droit Ã  l'oubli** : Suppression compte + donnÃ©es (dÃ©lai 90j)
4. **Droit Ã  la portabilitÃ©** : Export JSON complet (conversations, feedbacks)

#### DurÃ©es de RÃ©tention

| DonnÃ©es | DurÃ©e | Base lÃ©gale |
|---------|-------|-------------|
| Conversations | 2 ans | IntÃ©rÃªt lÃ©gitime (amÃ©lioration service) |
| Feedbacks | 3 ans | IntÃ©rÃªt lÃ©gitime (qualitÃ©) |
| Logs systÃ¨me | 6 mois | Obligation lÃ©gale (sÃ©curitÃ©) |
| Factures | 10 ans | Obligation lÃ©gale (comptabilitÃ©) |

**Purge automatique** : Cron hebdomadaire (dimanche 5h UTC)

```bash
# Script : /opt/qadhya/gdpr-purge.sh
psql -U moncabinet -d qadhya -c "
  DELETE FROM conversations WHERE created_at < NOW() - INTERVAL '2 years';
  DELETE FROM rag_feedback WHERE created_at < NOW() - INTERVAL '3 years';
  DELETE FROM ai_usage_logs WHERE created_at < NOW() - INTERVAL '6 months';
"
```

---

## 9. Troubleshooting

### 9.1 ProblÃ¨mes FrÃ©quents

#### Erreur : "Service Ollama indisponible"

**SymptÃ´mes** :
- Mode Rapide Ã©choue systÃ©matiquement
- Logs : `"Ollama request failed: connect ECONNREFUSED"`

**Diagnostic** :
```bash
systemctl status ollama
curl http://host.docker.internal:11434/api/version
```

**Solutions** :
1. **Ollama down** : `systemctl restart ollama`
2. **Port bloquÃ©** : VÃ©rifier UFW `ufw status | grep 11434`
3. **Container isolation** : VÃ©rifier `extra_hosts` dans docker-compose.prod.yml

#### Erreur : "Database connection pool exhausted"

**SymptÃ´mes** :
- RequÃªtes lentes ou timeout
- Logs : `"Error: remaining connection slots are reserved"`

**Diagnostic** :
```sql
SELECT count(*) FROM pg_stat_activity;
SELECT max_connections FROM pg_settings;
```

**Solutions** :
1. **Augmenter pool** : `.env` â†’ `DATABASE_POOL_SIZE=20` (dÃ©faut 10)
2. **Tuning PostgreSQL** : `max_connections=100` dans `postgresql.conf`
3. **Tuer connexions idle** :
   ```sql
   SELECT pg_terminate_backend(pid) FROM pg_stat_activity
   WHERE state = 'idle' AND state_change < NOW() - INTERVAL '10 minutes';
   ```

#### Erreur : "Indexation bloquÃ©e (0 docs/heure)"

**SymptÃ´mes** :
- Cron indexation runs mais 0 docs indexÃ©s
- Logs : `"No documents to index"`

**Diagnostic** :
```sql
-- VÃ©rifier jobs orphelins
SELECT * FROM indexing_jobs WHERE status = 'running' AND started_at < NOW() - INTERVAL '10 minutes';

-- VÃ©rifier docs en attente
SELECT COUNT(*) FROM knowledge_base WHERE is_indexed = false;
```

**Solutions** :
1. **Jobs orphelins** : Marquer failed manuellement
   ```sql
   UPDATE indexing_jobs SET status = 'failed', error = 'Timeout (orphaned)'
   WHERE status = 'running' AND started_at < NOW() - INTERVAL '10 minutes';
   ```
2. **Re-dÃ©clencher** : `curl -X POST https://qadhya.tn/api/admin/index-kb`

### 9.2 Logs SystÃ¨me

#### AccÃ©der aux Logs

```bash
# Logs Next.js (app)
docker logs -f qadhya-nextjs --tail 100

# Logs PostgreSQL
docker logs -f qadhya-postgres --tail 50

# Logs Ollama
journalctl -u ollama -f

# Logs Nginx
tail -f /var/log/nginx/access.log
tail -f /var/log/nginx/error.log

# Logs indexation KB
tail -f /var/log/kb-indexing.log
```

#### Filtrer Erreurs Critiques

```bash
# Erreurs Next.js (derniÃ¨res 24h)
docker logs qadhya-nextjs --since 24h | grep -i "error"

# Timeouts PostgreSQL
docker logs qadhya-postgres --since 24h | grep -i "timeout"

# Fallback LLM (Ã©checs Ollama)
docker logs qadhya-nextjs --since 1h | grep "LLM-Fallback"
```

---

## 10. Maintenance

### 10.1 Checklist Hebdomadaire

- [ ] **VÃ©rifier mÃ©triques dashboard** (latency, error rate, coÃ»t)
- [ ] **Valider 50 docs KB** (quality review queue)
- [ ] **Analyser feedbacks nÃ©gatifs** (rating â‰¤2 Ã©toiles)
- [ ] **VÃ©rifier sauvegardes** (PostgreSQL, MinIO)
- [ ] **Purger cache Redis** si hit rate <50%
- [ ] **Reindex PostgreSQL** : `VACUUM ANALYZE VERBOSE;`
- [ ] **VÃ©rifier espace disque** : `df -h | grep /opt/qadhya`

### 10.2 Checklist Mensuelle

- [ ] **Audit sÃ©curitÃ©** : VÃ©rifier `audit_logs` pour actions suspectes
- [ ] **Update packages NPM** : `npm outdated` â†’ Upgrade mineur
- [ ] **Mise Ã  jour Ollama** : `ollama pull qwen2.5:3b` + `qwen3-embedding:0.6b`
- [ ] **Analyse coÃ»ts LLM** : Dashboard provider usage â†’ Optimiser fallback chain
- [ ] **Test restauration backup** : Valider 1 backup PostgreSQL au hasard
- [ ] **Nettoyage Docker** : `docker system prune -a` (images/containers inutilisÃ©s)
- [ ] **Rapport mensuel direction** : Export mÃ©triques qualitÃ© + coÃ»ts

### 10.3 Updates Production

#### DÃ©ploiement sans Downtime (Rolling Update)

**âš ï¸ PrÃ©requis** : 2+ instances Next.js (load balancer Nginx)

```bash
# 1. Build nouvelle version
git pull origin main
npm run build

# 2. Tag Docker
docker build -t qadhya:v1.2.0 .
docker tag qadhya:v1.2.0 qadhya:latest

# 3. Update instance 1
docker stop qadhya-nextjs-1
docker rm qadhya-nextjs-1
docker-compose up -d qadhya-nextjs-1

# 4. Health check instance 1
curl https://qadhya.tn/api/health

# 5. Si OK, update instance 2
docker stop qadhya-nextjs-2
docker rm qadhya-nextjs-2
docker-compose up -d qadhya-nextjs-2
```

#### Maintenance PlanifiÃ©e (Page Maintenance)

```bash
# Activer page maintenance
npm run maintenance:setup

# ArrÃªter containers
docker-compose -f docker-compose.prod.yml down

# Effectuer maintenance (migrations DB, updates, etc.)
# ...

# RedÃ©marrer
docker-compose -f docker-compose.prod.yml up -d

# DÃ©sactiver page maintenance (automatique dÃ¨s que Next.js rÃ©pond)
```

**Communication** : Email 48h avant maintenance (date/heure/durÃ©e estimÃ©e)

---

## ğŸ“ Support Niveau 3

**Escalade si** :
- Erreur non documentÃ©e dans ce guide
- Corruption base de donnÃ©es
- Faille sÃ©curitÃ© dÃ©tectÃ©e
- Incident majeur (>30min downtime)

**Contact** :
- **Email** : devops@qadhya.tn
- **TÃ©lÃ©phone urgence** : +216 XX XXX XXX (disponible 24/7)
- **Slack** : #qadhya-ops (rÃ©ponse <30min)

---

**Version** : 1.0
**DerniÃ¨re mise Ã  jour** : 11 FÃ©vrier 2026
**Auteur** : Ã‰quipe Qadhya DevOps
**Licence** : Usage interne administrateurs uniquement
