# üéØ Configuration IA par Type d'Op√©ration - Qadhya

> **Organisation optimale des mod√®les IA selon les op√©rations m√©tier**
> **Date** : 11 f√©vrier 2026

---

## üìä Vue d'ensemble du syst√®me

### Providers disponibles

| Provider | Mod√®le | Latence | Co√ªt | Sp√©cialit√© |
|----------|--------|---------|------|------------|
| **Groq** | llama-3.3-70b | 292ms | 0‚Ç¨ | ‚ö° Chat ultra-rapide |
| **Gemini** | 2.5-flash | 1,5s | 0‚Ç¨ | üåç Multilingue AR/FR |
| **DeepSeek** | deepseek-chat | 1,8s | ~0.001‚Ç¨ | üìù Extraction structur√©e |
| **OpenAI** | text-embedding-3-small | 500ms | ~0.0001‚Ç¨ | üîç Embeddings de qualit√© |
| **Ollama** | qwen2.5:3b | 18s | 0‚Ç¨ | üè† Backup local |
| **Ollama** | qwen3-embedding:0.6b | 2s | 0‚Ç¨ | üîç Embeddings gratuit |

---

## üóÇÔ∏è Configuration par Op√©ration

### 1Ô∏è‚É£ **INDEXATION** (Background processing)

**URL** : N/A (Cron jobs, API `/api/admin/index-kb`)
**Volume** : ~100-500 documents/jour
**Priorit√©** : Co√ªt > Vitesse (non critique)

#### Configuration recommand√©e

```typescript
{
  operation: 'indexation',

  // Extraction de contenu
  contentExtraction: {
    primary: 'ollama',      // Gratuit, volume √©lev√©
    fallback: ['groq'],
    model: 'qwen2.5:3b',
    timeout: 30000,         // 30s acceptable
  },

  // G√©n√©ration d'embeddings
  embeddings: {
    primary: 'ollama',      // Gratuit pour volume √©lev√©
    fallback: ['openai'],   // Qualit√© sup√©rieure si besoin
    model: 'qwen3-embedding:0.6b',
    dimensions: 1024,
    timeout: 10000,
  },

  // Analyse qualit√© document
  qualityAnalysis: {
    primary: 'gemini',      // Bon raisonnement
    fallback: ['deepseek', 'ollama'],
    model: 'gemini-2.5-flash',
    timeout: 15000,
  },

  // Classification juridique
  legalClassification: {
    primary: 'deepseek',    // Excellent extraction
    fallback: ['gemini', 'ollama'],
    model: 'deepseek-chat',
    timeout: 10000,
  },
}
```

**Estimation co√ªts** :
- 500 docs/jour √ó 30 jours = 15,000 docs/mois
- 95% Ollama (gratuit) + 5% fallback = **~2‚Ç¨/mois**

---

### 2Ô∏è‚É£ **ASSISTANT IA** (`/assistant-ia`)

**URL** : https://qadhya.tn/assistant-ia
**Volume** : ~1,000-2,000 questions/jour
**Priorit√©** : Vitesse ‚ö° + Exp√©rience utilisateur

#### Configuration recommand√©e

```typescript
{
  operation: 'assistant-ia',
  url: '/assistant-ia',

  // Recherche dans la base de connaissances
  ragSearch: {
    // 1. G√©n√©ration embedding de la question
    queryEmbedding: {
      primary: 'ollama',      // Rapide + gratuit
      fallback: ['openai'],
      model: 'qwen3-embedding:0.6b',
      timeout: 3000,
    },

    // 2. Recherche vectorielle PostgreSQL
    vectorSearch: {
      method: 'pgvector',
      limit: 10,              // Top 10 r√©sultats
      threshold: 0.7,
    },
  },

  // G√©n√©ration de la r√©ponse
  chatGeneration: {
    primary: 'groq',          // ‚ö° ULTRA RAPIDE (292ms)
    fallback: ['gemini', 'ollama'],
    model: 'llama-3.3-70b-versatile',
    temperature: 0.3,
    maxTokens: 500,
    timeout: 5000,            // Max 5s pour UX
  },

  // Mode premium (opt-in utilisateur)
  premiumMode: {
    primary: 'gemini',        // Meilleure qualit√©
    fallback: ['groq', 'deepseek'],
    model: 'gemini-2.5-flash',
    temperature: 0.2,
    maxTokens: 1000,
  },
}
```

**Parcours utilisateur** :
```
Question utilisateur
    ‚¨áÔ∏è  (Ollama 2s)
Embedding de la question
    ‚¨áÔ∏è  (PostgreSQL 100ms)
Recherche vectorielle (10 r√©sultats)
    ‚¨áÔ∏è  (Groq 292ms)
G√©n√©ration r√©ponse contextualis√©e
    ‚¨áÔ∏è
R√©ponse √† l'utilisateur (TOTAL: ~2.5s)
```

**Estimation co√ªts** :
- 2,000 questions/jour √ó 30 = 60,000 questions/mois
- 100% gratuit (Ollama + Groq)
- **0‚Ç¨/mois** üéâ

---

### 3Ô∏è‚É£ **ASSISTANT DOSSIERS** (`/dossiers/assistant`)

**URL** : https://qadhya.tn/dossiers/assistant
**Volume** : ~200-500 requ√™tes/jour
**Priorit√©** : Qualit√© > Vitesse (analyse approfondie)

#### Configuration recommand√©e

```typescript
{
  operation: 'dossiers-assistant',
  url: '/dossiers/assistant',

  // Analyse du dossier complet
  dossierAnalysis: {
    primary: 'gemini',        // Excellent raisonnement
    fallback: ['groq', 'deepseek'],
    model: 'gemini-2.5-flash',
    temperature: 0.2,
    maxTokens: 2000,          // R√©ponses d√©taill√©es
    timeout: 15000,           // 15s acceptable
  },

  // Extraction d'informations structur√©es
  structuredExtraction: {
    primary: 'deepseek',      // Meilleur pour JSON
    fallback: ['gemini'],
    model: 'deepseek-chat',
    responseFormat: 'json',
    timeout: 10000,
  },

  // Recherche jurisprudence pertinente
  jurisprudenceSearch: {
    queryEmbedding: {
      primary: 'openai',      // Qualit√© sup√©rieure
      fallback: ['ollama'],
      model: 'text-embedding-3-small',
      dimensions: 1536,
    },
    vectorSearch: {
      method: 'pgvector',
      limit: 20,              // Plus de r√©sultats
      threshold: 0.65,        // Moins strict
    },
  },

  // Synth√®se juridique
  legalSummary: {
    primary: 'gemini',        // Multilingue AR/FR
    fallback: ['groq'],
    model: 'gemini-2.5-flash',
    temperature: 0.1,         // Tr√®s factuel
    maxTokens: 1500,
  },
}
```

**Parcours utilisateur** :
```
Ouverture dossier
    ‚¨áÔ∏è  (Gemini 1.5s)
Analyse contexte juridique
    ‚¨áÔ∏è  (OpenAI 500ms)
Recherche jurisprudence (embedding)
    ‚¨áÔ∏è  (PostgreSQL 200ms)
Recherche vectorielle
    ‚¨áÔ∏è  (Gemini 2s)
Synth√®se argumentaire
    ‚¨áÔ∏è
Suggestions √† l'utilisateur (TOTAL: ~4.2s)
```

**Estimation co√ªts** :
- 500 dossiers/jour √ó 30 = 15,000 analyses/mois
- OpenAI embeddings : 15,000 √ó 0.0001‚Ç¨ = 1.50‚Ç¨
- Autres : gratuit (Gemini/Groq)
- **~1.50‚Ç¨/mois**

---

### 4Ô∏è‚É£ **CONSULTATION DOSSIERS** (`/dossiers/consultation`)

**URL** : https://qadhya.tn/dossiers/consultation
**Volume** : ~100-200 consultations/jour
**Priorit√©** : Qualit√© maximale + M√©thodologie IRAC

#### Configuration recommand√©e

```typescript
{
  operation: 'dossiers-consultation',
  url: '/dossiers/consultation',

  // G√©n√©ration consultation formelle (m√©thode IRAC)
  formalConsultation: {
    primary: 'gemini',        // Meilleur raisonnement structur√©
    fallback: ['deepseek', 'groq'],
    model: 'gemini-2.5-flash',
    temperature: 0.1,         // Tr√®s factuel
    maxTokens: 4000,          // Consultations longues
    timeout: 30000,           // 30s acceptable
    systemPrompt: 'legal-reasoning-irac',
  },

  // Recherche textes l√©gislatifs
  legislationSearch: {
    queryEmbedding: {
      primary: 'openai',      // Pr√©cision maximale
      fallback: ['ollama'],
      model: 'text-embedding-3-small',
    },
    vectorSearch: {
      method: 'pgvector',
      limit: 30,              // Beaucoup de r√©sultats
      threshold: 0.6,         // Large filet
      filters: {
        category: ['legislation', 'jurisprudence'],
      },
    },
  },

  // V√©rification coh√©rence juridique
  coherenceCheck: {
    primary: 'deepseek',      // Analyse fine
    fallback: ['gemini'],
    model: 'deepseek-chat',
    temperature: 0.05,        // Tr√®s strict
  },

  // G√©n√©ration document final (FR + AR)
  documentGeneration: {
    primary: 'gemini',        // Meilleur bilingue
    fallback: ['groq'],
    model: 'gemini-2.5-flash',
    temperature: 0.2,
  },
}
```

**Parcours utilisateur** :
```
Demande consultation
    ‚¨áÔ∏è  (OpenAI 500ms)
Recherche l√©gislation pertinente
    ‚¨áÔ∏è  (PostgreSQL 300ms)
Recherche vectorielle multi-sources
    ‚¨áÔ∏è  (Gemini 10s)
R√©daction consultation IRAC
    ‚¨áÔ∏è  (DeepSeek 2s)
V√©rification coh√©rence
    ‚¨áÔ∏è  (Gemini 3s)
G√©n√©ration PDF FR + AR
    ‚¨áÔ∏è
Consultation livr√©e (TOTAL: ~15-20s)
```

**Estimation co√ªts** :
- 200 consultations/jour √ó 30 = 6,000 consultations/mois
- OpenAI embeddings : 6,000 √ó 0.0001‚Ç¨ = 0.60‚Ç¨
- Autres : gratuit (Gemini/DeepSeek)
- **~0.60‚Ç¨/mois**

---

## üìä Matrice r√©capitulative

| Op√©ration | Primary | Fallback | Latence | Co√ªt/mois | Volume/jour |
|-----------|---------|----------|---------|-----------|-------------|
| **Indexation** | Ollama | Groq | 30s | ~2‚Ç¨ | 100-500 docs |
| **Assistant IA** | Groq | Gemini | 2.5s | 0‚Ç¨ | 1,000-2,000 |
| **Assistant Dossiers** | Gemini | Groq | 4.2s | ~1.50‚Ç¨ | 200-500 |
| **Consultation** | Gemini | DeepSeek | 15-20s | ~0.60‚Ç¨ | 100-200 |
| **Embeddings** | Ollama | OpenAI | 2s | ~2.10‚Ç¨ | Tous |

**Total mensuel** : **~6.20‚Ç¨/mois** (vs 100‚Ç¨+ avec alternatives)

---

## üéØ Configuration code recommand√©e

### Fichier : `lib/ai/operations-config.ts`

```typescript
/**
 * Configuration IA par op√©ration m√©tier
 */

export const AI_OPERATIONS_CONFIG = {
  // 1. Indexation (background)
  indexation: {
    contentExtraction: {
      provider: 'ollama',
      model: 'qwen2.5:3b',
      fallback: ['groq', 'gemini'],
      timeout: 30000,
    },
    embeddings: {
      provider: 'ollama',
      model: 'qwen3-embedding:0.6b',
      fallback: ['openai'],
      timeout: 10000,
    },
    qualityAnalysis: {
      provider: 'gemini',
      model: 'gemini-2.5-flash',
      fallback: ['deepseek', 'ollama'],
      timeout: 15000,
    },
    legalClassification: {
      provider: 'deepseek',
      model: 'deepseek-chat',
      fallback: ['gemini', 'ollama'],
      timeout: 10000,
    },
  },

  // 2. Assistant IA (/assistant-ia)
  'assistant-ia': {
    queryEmbedding: {
      provider: 'ollama',
      model: 'qwen3-embedding:0.6b',
      fallback: ['openai'],
      timeout: 3000,
    },
    chatGeneration: {
      provider: 'groq',             // ULTRA RAPIDE ‚ö°
      model: 'llama-3.3-70b-versatile',
      fallback: ['gemini', 'ollama'],
      temperature: 0.3,
      maxTokens: 500,
      timeout: 5000,
    },
    premiumMode: {
      provider: 'gemini',
      model: 'gemini-2.5-flash',
      fallback: ['groq', 'deepseek'],
      temperature: 0.2,
      maxTokens: 1000,
    },
  },

  // 3. Assistant Dossiers (/dossiers/assistant)
  'dossiers-assistant': {
    dossierAnalysis: {
      provider: 'gemini',
      model: 'gemini-2.5-flash',
      fallback: ['groq', 'deepseek'],
      temperature: 0.2,
      maxTokens: 2000,
      timeout: 15000,
    },
    structuredExtraction: {
      provider: 'deepseek',
      model: 'deepseek-chat',
      fallback: ['gemini'],
      responseFormat: 'json',
      timeout: 10000,
    },
    jurisprudenceSearch: {
      queryEmbedding: {
        provider: 'openai',         // Qualit√© sup√©rieure
        model: 'text-embedding-3-small',
        fallback: ['ollama'],
      },
    },
    legalSummary: {
      provider: 'gemini',
      model: 'gemini-2.5-flash',
      fallback: ['groq'],
      temperature: 0.1,
      maxTokens: 1500,
    },
  },

  // 4. Consultation Dossiers (/dossiers/consultation)
  'dossiers-consultation': {
    formalConsultation: {
      provider: 'gemini',
      model: 'gemini-2.5-flash',
      fallback: ['deepseek', 'groq'],
      temperature: 0.1,
      maxTokens: 4000,
      timeout: 30000,
      systemPrompt: 'legal-reasoning-irac',
    },
    legislationSearch: {
      queryEmbedding: {
        provider: 'openai',
        model: 'text-embedding-3-small',
        fallback: ['ollama'],
      },
      filters: {
        category: ['legislation', 'jurisprudence'],
      },
    },
    coherenceCheck: {
      provider: 'deepseek',
      model: 'deepseek-chat',
      fallback: ['gemini'],
      temperature: 0.05,
    },
    documentGeneration: {
      provider: 'gemini',
      model: 'gemini-2.5-flash',
      fallback: ['groq'],
      temperature: 0.2,
    },
  },
} as const

export type OperationType = keyof typeof AI_OPERATIONS_CONFIG
```

---

## üí° Points cl√©s de la strat√©gie

### ‚úÖ OpenAI int√©gr√©

- **Usage** : Embeddings de qualit√© pour dossiers/consultations
- **Co√ªt** : ~2‚Ç¨/mois (tr√®s raisonnable)
- **Fallback** : Ollama (gratuit mais qualit√© inf√©rieure)

### ‚úÖ Groq optimis√©

- **Usage principal** : Chat assistant IA (volume √©lev√©)
- **Raison** : 292ms ultra-rapide pour UX fluide
- **√âconomie** : 100% gratuit sur volume principal

### ‚úÖ Gemini strat√©gique

- **Usage** : Analyses juridiques complexes
- **Raison** : Meilleur raisonnement + multilingue AR/FR
- **Avantage** : Gratuit avec excellent contexte

### ‚úÖ DeepSeek cibl√©

- **Usage** : Extraction structur√©e + JSON
- **Raison** : Excellent pour donn√©es structur√©es
- **Co√ªt** : Minimal (~1‚Ç¨/mois)

### ‚úÖ Ollama √©conomique

- **Usage** : Indexation background + embeddings
- **Raison** : Volume √©lev√©, non critique
- **Avantage** : 100% gratuit, toujours disponible

---

## üöÄ Prochaines √©tapes

### Impl√©mentation (1-2 semaines)

1. **Cr√©er** `lib/ai/operations-config.ts`
2. **Modifier** routes pour utiliser config par op√©ration :
   - `/api/assistant-ia/route.ts`
   - `/api/dossiers/[id]/assistant/route.ts`
   - `/api/dossiers/[id]/consultation/route.ts`
   - `/api/admin/index-kb/route.ts`
3. **Tester** chaque op√©ration individuellement
4. **Monitorer** usage r√©el pendant 2 semaines
5. **Ajuster** selon m√©triques

### Validation

- [ ] Config test√©e sur dev
- [ ] Tests de charge OK
- [ ] Co√ªts valid√©s < 10‚Ç¨/mois
- [ ] Latences respect√©es
- [ ] Qualit√© valid√©e par utilisateurs

---

**Configuration valid√©e** : 11 f√©vrier 2026
**Co√ªt total estim√©** : **~6‚Ç¨/mois**
**√âconomie vs alternatives** : **~1,140‚Ç¨/an** üéâ
