#!/bin/bash
# Benchmark comparatif des modÃ¨les IA
# Compare : Ollama, Gemini, Groq, DeepSeek

set -e

echo "ğŸ¯ Benchmark des modÃ¨les IA - Question juridique"
echo "=================================================="
echo ""

# Question juridique en franÃ§ais
QUESTION="Un employeur peut-il licencier un salariÃ© pour faute grave sans prÃ©avis en Tunisie? RÃ©ponds en 2-3 phrases courtes."

echo "ğŸ“ Question posÃ©e :"
echo "   \"$QUESTION\""
echo ""

ssh root@84.247.165.187 << ENDSSH
set -e

# Source le fichier .env
source /opt/qadhya/.env.production.local

QUESTION="Un employeur peut-il licencier un salariÃ© pour faute grave sans prÃ©avis en Tunisie? RÃ©ponds en 2-3 phrases courtes."

echo "============================================================"
echo "1ï¸âƒ£  OLLAMA (qwen2.5:3b) - Local, Gratuit"
echo "============================================================"
START=\$(date +%s%N)
RESPONSE=\$(curl -s -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d "{
    \"model\": \"qwen2.5:3b\",
    \"prompt\": \"\$QUESTION\",
    \"stream\": false,
    \"options\": {
      \"temperature\": 0.3,
      \"num_predict\": 200
    }
  }" 2>&1)
END=\$(date +%s%N)
LATENCY=\$(( (END - START) / 1000000 ))

if echo "\$RESPONSE" | grep -q "response"; then
  ANSWER=\$(echo "\$RESPONSE" | grep -o '"response":"[^"]*"' | sed 's/"response":"//;s/"$//' | head -c 500)
  echo "â±ï¸  Latence: \${LATENCY}ms"
  echo "ğŸ’° CoÃ»t: 0â‚¬ (local)"
  echo "ğŸ“Š RÃ©ponse:"
  echo "\$ANSWER"
else
  echo "âŒ Ã‰CHEC"
fi

echo ""
echo "============================================================"
echo "2ï¸âƒ£  GEMINI (2.5-flash) - Gratuit"
echo "============================================================"
START=\$(date +%s%N)
RESPONSE=\$(curl -s -X POST \
  "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=\$GEMINI_API_KEY" \
  -H "Content-Type: application/json" \
  -d "{
    \"contents\": [{\"parts\": [{\"text\": \"\$QUESTION\"}]}],
    \"generationConfig\": {
      \"temperature\": 0.3,
      \"maxOutputTokens\": 200
    }
  }" 2>&1)
END=\$(date +%s%N)
LATENCY=\$(( (END - START) / 1000000 ))

if echo "\$RESPONSE" | grep -q "candidates"; then
  ANSWER=\$(echo "\$RESPONSE" | grep -o '"text":"[^"]*"' | sed 's/"text":"//;s/"$//' | head -c 500)
  echo "â±ï¸  Latence: \${LATENCY}ms"
  echo "ğŸ’° CoÃ»t: 0â‚¬ (gratuit)"
  echo "ğŸ“Š RÃ©ponse:"
  echo "\$ANSWER"
else
  echo "âŒ Ã‰CHEC"
fi

echo ""
echo "============================================================"
echo "3ï¸âƒ£  GROQ (llama-3.3-70b) - Gratuit"
echo "============================================================"
START=\$(date +%s%N)
RESPONSE=\$(curl -s -X POST https://api.groq.com/openai/v1/chat/completions \
  -H "Authorization: Bearer \$GROQ_API_KEY" \
  -H "Content-Type: application/json" \
  -d "{
    \"model\": \"llama-3.3-70b-versatile\",
    \"messages\": [{\"role\": \"user\", \"content\": \"\$QUESTION\"}],
    \"temperature\": 0.3,
    \"max_tokens\": 200
  }" 2>&1)
END=\$(date +%s%N)
LATENCY=\$(( (END - START) / 1000000 ))

if echo "\$RESPONSE" | grep -q "choices"; then
  ANSWER=\$(echo "\$RESPONSE" | grep -o '"content":"[^"]*"' | sed 's/"content":"//;s/"$//' | head -c 500)
  echo "â±ï¸  Latence: \${LATENCY}ms"
  echo "ğŸ’° CoÃ»t: 0â‚¬ (gratuit)"
  echo "ğŸ“Š RÃ©ponse:"
  echo "\$ANSWER"
else
  ERROR=\$(echo "\$RESPONSE" | head -c 200)
  echo "âŒ Ã‰CHEC: \$ERROR"
fi

echo ""
echo "============================================================"
echo "4ï¸âƒ£  DEEPSEEK (deepseek-chat) - Payant (trÃ¨s bon rapport qualitÃ©/prix)"
echo "============================================================"
START=\$(date +%s%N)
RESPONSE=\$(curl -s -X POST https://api.deepseek.com/v1/chat/completions \
  -H "Authorization: Bearer \$DEEPSEEK_API_KEY" \
  -H "Content-Type: application/json" \
  -d "{
    \"model\": \"deepseek-chat\",
    \"messages\": [{\"role\": \"user\", \"content\": \"\$QUESTION\"}],
    \"temperature\": 0.3,
    \"max_tokens\": 200
  }" 2>&1)
END=\$(date +%s%N)
LATENCY=\$(( (END - START) / 1000000 ))

if echo "\$RESPONSE" | grep -q "choices"; then
  ANSWER=\$(echo "\$RESPONSE" | grep -o '"content":"[^"]*"' | sed 's/"content":"//;s/"$//' | head -c 500)
  echo "â±ï¸  Latence: \${LATENCY}ms"
  echo "ğŸ’° CoÃ»t: ~0.001â‚¬ par requÃªte"
  echo "ğŸ“Š RÃ©ponse:"
  echo "\$ANSWER"
else
  ERROR=\$(echo "\$RESPONSE" | head -c 200)
  echo "âŒ Ã‰CHEC: \$ERROR"
fi

echo ""
echo "============================================================"
echo "ğŸ“Š SYNTHÃˆSE DU BENCHMARK"
echo "============================================================"
echo ""
echo "CritÃ¨res d'Ã©valuation :"
echo "  ğŸš€ Vitesse      : Temps de rÃ©ponse (ms)"
echo "  ğŸ’° CoÃ»t         : Prix par requÃªte"
echo "  ğŸ“ QualitÃ©      : Pertinence et prÃ©cision"
echo "  ğŸŒ Langue       : Support du franÃ§ais"
echo ""
echo "Recommandations selon l'usage :"
echo ""
echo "  Mode RAPIDE (0â‚¬) :"
echo "    1ï¸âƒ£  Ollama    : Bon pour usage intensif, 100% gratuit"
echo "    2ï¸âƒ£  Groq      : TrÃ¨s rapide, excellent rapport qualitÃ©/vitesse"
echo "    3ï¸âƒ£  Gemini    : Bon Ã©quilibre, gratuit"
echo ""
echo "  Mode PREMIUM (payant) :"
echo "    1ï¸âƒ£  DeepSeek  : Meilleur rapport qualitÃ©/prix (0.001â‚¬)"
echo "    2ï¸âƒ£  Gemini    : Alternative gratuite de bonne qualitÃ©"
echo ""
echo "ğŸ’¡ Configuration actuelle de l'app :"
echo "    â€¢ Mode Rapide : Ollama (par dÃ©faut)"
echo "    â€¢ Mode Premium : Gemini â†’ Groq â†’ DeepSeek (cascade)"
echo ""

ENDSSH

echo ""
echo "âœ… Benchmark terminÃ© !"
echo ""
echo "ğŸ“Œ Note : OpenAI n'est pas inclus car configurÃ© uniquement pour embeddings"
