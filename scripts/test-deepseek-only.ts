#!/usr/bin/env tsx
import { config } from 'dotenv'
config({ path: '.env.local' })

import { callLLMWithFallback } from '../lib/ai/llm-fallback-service'

async function testDeepSeek() {
  console.log('ğŸ§ª Test clÃ© DeepSeek aprÃ¨s recharge solde\n')

  const apiKey = process.env.DEEPSEEK_API_KEY
  if (!apiKey) {
    console.error('âŒ DEEPSEEK_API_KEY non trouvÃ©e')
    process.exit(1)
  }

  console.log(`ğŸ”‘ ClÃ©: ${apiKey.substring(0, 10)}...${apiKey.slice(-6)}`)

  try {
    console.log('\nğŸ“¡ Appel DeepSeek via callLLMWithFallback...')
    
    const start = Date.now()
    const response = await callLLMWithFallback(
      [{ role: 'user', content: 'RÃ©ponds juste "OK" en un mot.' }],
      {
        temperature: 0,
        maxTokens: 10,
        context: 'quality-analysis' // Force DeepSeek comme premier choix
      },
      false
    )
    const duration = Date.now() - start

    console.log('\nâœ… DeepSeek fonctionne!')
    console.log(`ğŸ“ RÃ©ponse: "${response.answer}"`)
    console.log(`â±ï¸  DurÃ©e: ${duration}ms`)
    console.log(`ğŸ“Š ModÃ¨le: ${response.modelUsed}`)
    console.log(`ğŸ”¢ Tokens: ${response.tokensUsed.total}`)
    console.log(`ğŸ¯ Provider: ${response.provider}`)
    
    if (response.fallbackUsed && response.originalProvider !== response.provider) {
      console.log(`\nâš ï¸  Fallback utilisÃ©: ${response.originalProvider} â†’ ${response.provider}`)
    }

    process.exit(0)
  } catch (error) {
    console.error(`\nâŒ Erreur: ${getErrorMessage(error)}`)
    process.exit(1)
  }
}

testDeepSeek()
