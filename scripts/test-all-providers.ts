#!/usr/bin/env tsx
/**
 * Test complet de tous les providers LLM et du systÃ¨me de fallback
 */

// Charger .env.local avant toute autre chose
import { config } from 'dotenv'
config({ path: '.env.local' })

import { callLLMWithFallback, getAvailableProviders } from '../lib/ai/llm-fallback-service'
import { callGemini } from '../lib/ai/gemini-client'
import { getApiKey, listApiKeys } from '../lib/api-keys/api-keys-service'

interface TestResult {
  name: string
  status: 'âœ…' | 'âŒ' | 'â­ï¸'
  message: string
  duration?: number
}

const results: TestResult[] = []

function addResult(name: string, status: 'âœ…' | 'âŒ' | 'â­ï¸', message: string, duration?: number) {
  results.push({ name, status, message, duration })
}

async function testApiKeysDB() {
  console.log('\nğŸ” Test 1: RÃ©cupÃ©ration des clÃ©s depuis la base de donnÃ©es\n')

  try {
    const keys = await listApiKeys()
    console.log(`  ğŸ“‹ ${keys.length} clÃ©(s) trouvÃ©e(s) dans la base :`)

    for (const key of keys) {
      const emoji = key.isPrimary ? 'ğŸ†' : key.isActive ? 'âœ…' : 'âŒ'
      console.log(`    ${emoji} ${key.provider.padEnd(10)} â†’ ${key.apiKeyMasked} (${key.tier})`)
    }

    // Test rÃ©cupÃ©ration clÃ©s dÃ©chiffrÃ©es
    const geminiKey = await getApiKey('gemini')
    const deepseekKey = await getApiKey('deepseek')

    if (geminiKey) {
      addResult('DB: Gemini Key', 'âœ…', `ClÃ© rÃ©cupÃ©rÃ©e (${geminiKey.length} chars)`)
    } else {
      addResult('DB: Gemini Key', 'âŒ', 'ClÃ© non trouvÃ©e')
    }

    if (deepseekKey) {
      addResult('DB: DeepSeek Key', 'âœ…', `ClÃ© rÃ©cupÃ©rÃ©e (${deepseekKey.length} chars)`)
    } else {
      addResult('DB: DeepSeek Key', 'âŒ', 'ClÃ© non trouvÃ©e')
    }

  } catch (error: any) {
    addResult('DB: RÃ©cupÃ©ration clÃ©s', 'âŒ', error.message)
  }
}

async function testGeminiDirect() {
  console.log('\nğŸ¤– Test 2: Appel direct Gemini\n')

  try {
    const start = Date.now()
    const response = await callGemini(
      [{ role: 'user', content: 'Dis juste "OK" en un mot.' }],
      { temperature: 0, maxTokens: 10 }
    )
    const duration = Date.now() - start

    console.log(`  âœ… RÃ©ponse: "${response.answer}"`)
    console.log(`  â±ï¸  DurÃ©e: ${duration}ms`)
    console.log(`  ğŸ“Š ModÃ¨le: ${response.modelUsed}`)
    console.log(`  ğŸ“ˆ Tokens: ${response.tokensUsed.total}`)

    addResult('Gemini Direct', 'âœ…', `${duration}ms - "${response.answer}"`, duration)
  } catch (error: any) {
    console.log(`  âŒ Erreur: ${error.message}`)
    addResult('Gemini Direct', 'âŒ', error.message)
  }
}

async function testAvailableProviders() {
  console.log('\nğŸ” Test 3: Providers disponibles\n')

  try {
    const providers = getAvailableProviders()
    console.log(`  ğŸ“‹ ${providers.length} provider(s) disponible(s):`)

    for (const provider of providers) {
      console.log(`    âœ… ${provider}`)
    }

    addResult('Providers Available', 'âœ…', `${providers.length} providers: ${providers.join(', ')}`)
  } catch (error: any) {
    addResult('Providers Available', 'âŒ', error.message)
  }
}

async function testFallbackByContext() {
  console.log('\nğŸ”„ Test 4: Fallback par contexte\n')

  const contexts = [
    { name: 'rag-chat', expectedOrder: 'Gemini â†’ DeepSeek â†’ Ollama' },
    { name: 'quality-analysis', expectedOrder: 'DeepSeek â†’ Gemini â†’ Ollama' },
    { name: 'translation', expectedOrder: 'Gemini â†’ Groq' },
  ]

  for (const ctx of contexts) {
    try {
      console.log(`\n  ğŸ¯ Contexte: ${ctx.name}`)
      console.log(`     Ordre attendu: ${ctx.expectedOrder}`)

      const start = Date.now()
      const response = await callLLMWithFallback(
        [{ role: 'user', content: 'RÃ©ponds juste "OK".' }],
        {
          temperature: 0,
          maxTokens: 10,
          context: ctx.name as any
        },
        false // Mode Rapide
      )
      const duration = Date.now() - start

      console.log(`     âœ… Provider utilisÃ©: ${response.provider}`)
      console.log(`     â±ï¸  DurÃ©e: ${duration}ms`)
      console.log(`     ğŸ’¬ RÃ©ponse: "${response.answer}"`)

      addResult(`Fallback: ${ctx.name}`, 'âœ…', `${response.provider} - ${duration}ms`, duration)
    } catch (error: any) {
      console.log(`     âŒ Erreur: ${error.message}`)
      addResult(`Fallback: ${ctx.name}`, 'âŒ', error.message)
    }
  }
}

async function testModePremium() {
  console.log('\nğŸ’ Test 5: Mode Premium (skip Ollama)\n')

  try {
    const start = Date.now()
    const response = await callLLMWithFallback(
      [{ role: 'user', content: 'RÃ©ponds juste "OK".' }],
      { temperature: 0, maxTokens: 10, context: 'rag-chat' },
      true // Mode Premium
    )
    const duration = Date.now() - start

    console.log(`  âœ… Provider utilisÃ©: ${response.provider}`)
    console.log(`  â±ï¸  DurÃ©e: ${duration}ms`)
    console.log(`  ğŸ’¬ RÃ©ponse: "${response.answer}"`)

    if (response.provider === 'ollama') {
      addResult('Mode Premium', 'âŒ', 'Ollama ne devrait pas Ãªtre utilisÃ© en mode Premium')
    } else {
      addResult('Mode Premium', 'âœ…', `${response.provider} - ${duration}ms (pas Ollama)`, duration)
    }
  } catch (error: any) {
    console.log(`  âŒ Erreur: ${error.message}`)
    addResult('Mode Premium', 'âŒ', error.message)
  }
}

async function testOllama() {
  console.log('\nğŸ¦™ Test 6: Ollama local\n')
  console.log('  â„¹ï¸  Ollama est un fallback local optionnel (production = cloud providers)')
  console.log('  ğŸ’¡ Pour tester : `ollama serve` puis relancer ce script\n')

  try {
    // Forcer Ollama en dÃ©sactivant les autres providers temporairement
    process.env.GOOGLE_API_KEY = ''
    process.env.DEEPSEEK_API_KEY = ''

    const start = Date.now()
    const response = await callLLMWithFallback(
      [{ role: 'user', content: 'RÃ©ponds juste "OK".' }],
      { temperature: 0, maxTokens: 10 },
      false
    )
    const duration = Date.now() - start

    // Restaurer les clÃ©s
    config({ path: '.env.local', override: true })

    if (response.provider === 'ollama') {
      console.log(`  âœ… Provider utilisÃ©: ollama`)
      console.log(`  â±ï¸  DurÃ©e: ${duration}ms`)
      console.log(`  ğŸ’¬ RÃ©ponse: "${response.answer}"`)
      console.log(`  ğŸ“Š ModÃ¨le: ${response.modelUsed}`)
      addResult('Ollama Local', 'âœ…', `${duration}ms - fallback fonctionne`, duration)
    } else {
      console.log(`  âŒ Provider utilisÃ©: ${response.provider} (attendu: ollama)`)
      addResult('Ollama Local', 'âŒ', `${response.provider} utilisÃ© au lieu d'Ollama`)
    }
  } catch (error: any) {
    console.log(`  â­ï¸  Ollama non dÃ©marrÃ© (comportement attendu)`)
    console.log(`     â†’ Le systÃ¨me utilise les providers cloud (Gemini, DeepSeek)`)
    console.log(`     â†’ Ollama est utilisÃ© uniquement pour les embeddings (production)`)
    addResult('Ollama Local', 'â­ï¸', 'Non dÃ©marrÃ© - cloud providers actifs (OK)')
  }
}

function printSummary() {
  console.log('\n' + '='.repeat(70))
  console.log('ğŸ“Š RÃ‰SUMÃ‰ DES TESTS')
  console.log('='.repeat(70) + '\n')

  const passed = results.filter(r => r.status === 'âœ…').length
  const failed = results.filter(r => r.status === 'âŒ').length
  const skipped = results.filter(r => r.status === 'â­ï¸').length
  const total = results.length

  for (const result of results) {
    const duration = result.duration ? ` (${result.duration}ms)` : ''
    console.log(`${result.status} ${result.name.padEnd(30)} â†’ ${result.message}${duration}`)
  }

  console.log('\n' + '-'.repeat(70))
  console.log(`âœ… RÃ©ussis: ${passed}/${total}`)
  console.log(`âŒ Ã‰chouÃ©s: ${failed}/${total}`)
  console.log(`â­ï¸  IgnorÃ©s: ${skipped}/${total}`)
  console.log('-'.repeat(70) + '\n')

  if (failed > 0) {
    console.log('âš ï¸  Certains tests ont Ã©chouÃ©. VÃ©rifiez les clÃ©s API et la configuration.\n')
    process.exit(1)
  } else if (passed === total) {
    console.log('ğŸ‰ Tous les tests sont passÃ©s avec succÃ¨s!\n')
    process.exit(0)
  } else {
    console.log('âœ… Tests principaux rÃ©ussis (quelques tests ignorÃ©s).\n')
    process.exit(0)
  }
}

async function main() {
  console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—')
  console.log('â•‘        TEST COMPLET DES PROVIDERS LLM ET FALLBACK                 â•‘')
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')

  await testApiKeysDB()
  await testGeminiDirect()
  await testAvailableProviders()
  await testFallbackByContext()
  await testModePremium()
  await testOllama()

  printSummary()
}

main().catch((err) => {
  console.error('\nâŒ Erreur fatale:', err)
  process.exit(1)
})
