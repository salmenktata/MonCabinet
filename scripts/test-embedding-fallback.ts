/**
 * Script de test pour le mode turbo embeddings et le fallback OpenAI
 *
 * Tests :
 * 1. Embedding OpenAI seul â†’ vÃ©rifier 1024 dimensions
 * 2. Embedding Ollama â†’ vÃ©rifier fonctionnement normal
 * 3. Fallback auto â†’ simuler circuit breaker OPEN â†’ vÃ©rifier bascule OpenAI
 * 4. Info provider â†’ vÃ©rifier les mÃ©tadonnÃ©es retournÃ©es
 *
 * Usage :
 *   npx tsx scripts/test-embedding-fallback.ts
 *
 * PrÃ©requis :
 *   - OPENAI_API_KEY dans .env.local (pour tests OpenAI)
 *   - OLLAMA_ENABLED=true + ollama serve (pour tests Ollama)
 *   - RAG_ENABLED=true
 */

import 'dotenv/config'

// Forcer RAG_ENABLED pour les tests
process.env.RAG_ENABLED = 'true'

const SAMPLE_TEXT = 'Ø§Ù„Ù…Ø­ÙƒÙ…Ø© Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ© Ø¨ØªÙˆÙ†Ø³ ØªØµØ¯Ø± Ø­ÙƒÙ…Ù‹Ø§ ÙÙŠ Ù‚Ø¶ÙŠØ© Ø§Ù„Ø·Ù„Ø§Ù‚ ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„ÙØµÙ„ 31 Ù…Ù† Ù…Ø¬Ù„Ø© Ø§Ù„Ø£Ø­ÙˆØ§Ù„ Ø§Ù„Ø´Ø®ØµÙŠØ©'
const SAMPLE_TEXT_2 = 'Le tribunal de premiÃ¨re instance de Tunis statue en matiÃ¨re de divorce conformÃ©ment Ã  l\'article 31 du Code du Statut Personnel'

interface TestResult {
  name: string
  passed: boolean
  details: string
  duration?: number
}

const results: TestResult[] = []

function log(msg: string) {
  console.log(`  ${msg}`)
}

async function runTest(name: string, fn: () => Promise<void>) {
  console.log(`\nðŸ”¬ Test: ${name}`)
  const start = Date.now()
  try {
    await fn()
    const duration = Date.now() - start
    results.push({ name, passed: true, details: 'OK', duration })
    console.log(`  âœ… PASS (${duration}ms)`)
  } catch (error) {
    const duration = Date.now() - start
    const msg = error instanceof Error ? error.message : String(error)
    results.push({ name, passed: false, details: msg, duration })
    console.log(`  âŒ FAIL: ${msg} (${duration}ms)`)
  }
}

async function main() {
  console.log('='.repeat(60))
  console.log('  Test Embedding Fallback & Mode Turbo')
  console.log('='.repeat(60))

  const { aiConfig, getEmbeddingProvider, getEmbeddingFallbackProvider, EMBEDDING_TURBO_CONFIG } = await import('../lib/ai/config')

  console.log('\nðŸ“‹ Configuration dÃ©tectÃ©e :')
  console.log(`  Ollama enabled: ${aiConfig.ollama.enabled}`)
  console.log(`  OpenAI API key: ${aiConfig.openai.apiKey ? 'âœ… configurÃ©e' : 'âŒ manquante'}`)
  console.log(`  Provider principal: ${getEmbeddingProvider() || 'aucun'}`)
  console.log(`  Provider fallback: ${getEmbeddingFallbackProvider() || 'aucun'}`)
  console.log(`  Mode turbo: ${EMBEDDING_TURBO_CONFIG.enabled}`)
  console.log(`  OpenAI dimensions: ${aiConfig.openai.embeddingDimensions}`)

  // =========================================================================
  // Test 1 : Embedding OpenAI direct (si API key disponible)
  // =========================================================================
  if (aiConfig.openai.apiKey) {
    await runTest('OpenAI embedding direct (1024 dims)', async () => {
      const { generateEmbedding, validateEmbedding } = await import('../lib/ai/embeddings-service')

      const result = await generateEmbedding(SAMPLE_TEXT, { forceTurbo: true })

      if (result.embedding.length !== 1024) {
        throw new Error(`Dimensions incorrectes: ${result.embedding.length} (attendu: 1024)`)
      }
      if (result.provider !== 'openai') {
        throw new Error(`Provider incorrect: ${result.provider} (attendu: openai)`)
      }

      const validation = validateEmbedding(result.embedding, 'openai')
      if (!validation.valid) {
        throw new Error(`Validation Ã©chouÃ©e: ${validation.error}`)
      }

      log(`Provider: ${result.provider}`)
      log(`Dimensions: ${result.embedding.length}`)
      log(`Tokens: ${result.tokenCount}`)
      log(`Norme: ${Math.sqrt(result.embedding.reduce((s, v) => s + v * v, 0)).toFixed(4)}`)
    })

    // Test batch OpenAI
    await runTest('OpenAI batch embeddings (2 textes)', async () => {
      const { generateEmbeddingsBatch } = await import('../lib/ai/embeddings-service')

      const result = await generateEmbeddingsBatch(
        [SAMPLE_TEXT, SAMPLE_TEXT_2],
        { forceTurbo: true }
      )

      if (result.embeddings.length !== 2) {
        throw new Error(`Nombre embeddings incorrect: ${result.embeddings.length} (attendu: 2)`)
      }
      if (result.embeddings[0].length !== 1024) {
        throw new Error(`Dimensions incorrectes: ${result.embeddings[0].length} (attendu: 1024)`)
      }
      if (result.provider !== 'openai') {
        throw new Error(`Provider incorrect: ${result.provider} (attendu: openai)`)
      }

      log(`Provider: ${result.provider}`)
      log(`Embeddings: ${result.embeddings.length}`)
      log(`Total tokens: ${result.totalTokens}`)
    })
  } else {
    console.log('\nâš ï¸ OPENAI_API_KEY non configurÃ©e - Tests OpenAI ignorÃ©s')
    results.push({ name: 'OpenAI embedding direct', passed: true, details: 'IgnorÃ© (pas de clÃ© API)' })
    results.push({ name: 'OpenAI batch embeddings', passed: true, details: 'IgnorÃ© (pas de clÃ© API)' })
  }

  // =========================================================================
  // Test 2 : Embedding Ollama (si activÃ©)
  // =========================================================================
  if (aiConfig.ollama.enabled) {
    await runTest('Ollama embedding (mode normal)', async () => {
      const { generateEmbedding } = await import('../lib/ai/embeddings-service')

      const result = await generateEmbedding(SAMPLE_TEXT)

      if (result.embedding.length !== aiConfig.ollama.embeddingDimensions) {
        throw new Error(`Dimensions incorrectes: ${result.embedding.length} (attendu: ${aiConfig.ollama.embeddingDimensions})`)
      }
      if (result.provider !== 'ollama') {
        throw new Error(`Provider incorrect: ${result.provider} (attendu: ollama)`)
      }

      log(`Provider: ${result.provider}`)
      log(`Dimensions: ${result.embedding.length}`)
      log(`Tokens: ${result.tokenCount}`)
    })
  } else {
    console.log('\nâš ï¸ Ollama non activÃ© - Test Ollama ignorÃ©')
    results.push({ name: 'Ollama embedding', passed: true, details: 'IgnorÃ© (Ollama dÃ©sactivÃ©)' })
  }

  // =========================================================================
  // Test 3 : Info provider
  // =========================================================================
  await runTest('Provider info complÃ¨te', async () => {
    const { getEmbeddingProviderInfo } = await import('../lib/ai/embeddings-service')

    const info = getEmbeddingProviderInfo()

    if (!info.provider) {
      throw new Error('Aucun provider dÃ©tectÃ©')
    }

    log(`Provider: ${info.provider}`)
    log(`Model: ${info.model}`)
    log(`Dimensions: ${info.dimensions}`)
    log(`Cost: ${info.cost}`)
    log(`Turbo mode: ${info.turboMode}`)
    log(`Fallback: ${info.fallback || 'aucun'}`)
  })

  // =========================================================================
  // Test 4 : CompatibilitÃ© cross-provider (si les 2 sont dispos)
  // =========================================================================
  if (aiConfig.ollama.enabled && aiConfig.openai.apiKey) {
    await runTest('CompatibilitÃ© cross-provider (cosine similarity)', async () => {
      const { generateEmbedding, cosineSimilarity } = await import('../lib/ai/embeddings-service')

      // GÃ©nÃ©rer avec Ollama
      const ollamaResult = await generateEmbedding(SAMPLE_TEXT)

      // GÃ©nÃ©rer avec OpenAI (turbo)
      const openaiResult = await generateEmbedding(SAMPLE_TEXT, { forceTurbo: true })

      if (ollamaResult.embedding.length !== openaiResult.embedding.length) {
        throw new Error(
          `Dimensions incompatibles: Ollama=${ollamaResult.embedding.length}, ` +
          `OpenAI=${openaiResult.embedding.length}`
        )
      }

      // Calculer similaritÃ© (peut Ãªtre faible car modÃ¨les diffÃ©rents, mais les dimensions doivent matcher)
      const similarity = cosineSimilarity(ollamaResult.embedding, openaiResult.embedding)
      log(`SimilaritÃ© cosinus Ollama vs OpenAI: ${similarity.toFixed(4)}`)
      log(`(MÃªme texte, modÃ¨les diffÃ©rents â†’ similaritÃ© variable est normale)`)
      log(`Dimensions compatibles: âœ… (${ollamaResult.embedding.length})`)
    })
  }

  // =========================================================================
  // RÃ©sumÃ©
  // =========================================================================
  console.log('\n' + '='.repeat(60))
  console.log('  RÃ©sumÃ©')
  console.log('='.repeat(60))

  const passed = results.filter(r => r.passed).length
  const failed = results.filter(r => !r.passed).length

  for (const r of results) {
    const icon = r.passed ? 'âœ…' : 'âŒ'
    const time = r.duration ? ` (${r.duration}ms)` : ''
    console.log(`  ${icon} ${r.name}: ${r.details}${time}`)
  }

  console.log(`\n  Total: ${passed} passÃ©s, ${failed} Ã©chouÃ©s sur ${results.length}`)

  if (failed > 0) {
    process.exit(1)
  }
}

main().catch(error => {
  console.error('Erreur fatale:', error)
  process.exit(1)
})
